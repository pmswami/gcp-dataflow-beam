{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sSZwKTyEvmI4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17279af3-cb2e-4b0e-969d-2715af00b994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache_beam\n",
            "  Downloading apache_beam-2.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache_beam)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache_beam)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache_beam)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache_beam)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache_beam)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.64.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache_beam)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (4.23.0)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.2.2)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.26.4)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache_beam)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (24.1)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache_beam)\n",
            "  Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2024.1)\n",
            "Collecting redis<6,>=5.0.0 (from apache_beam)\n",
            "  Downloading redis-5.0.8-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2024.5.15)\n",
            "Collecting requests!=2.32.*,<3.0.0,>=2.24.0 (from apache_beam)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache_beam)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.6)\n",
            "Collecting js2py<1,>=0.74 (from apache_beam)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache_beam)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache_beam) (3.1.4)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache_beam) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache_beam)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (0.20.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache_beam)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache_beam) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache_beam) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache_beam) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache_beam) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache_beam) (2024.8.30)\n",
            "Downloading apache_beam-2.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.0.8-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: crcmod, dill, hdfs, pyjsparser, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31403 sha256=6b51af44ff8b73ab7db1393aa11e4db11529d1e074d0911d61fd6cecb2b71016\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=d2338e6f8ee0cb19551233c3e163d06f600bff7c26ce2683fd5c497476397db1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=867bfb3734f1e5dea9e617ec1c31ae14e0984c2ff920882a12ebd7d0e2bdc276\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25983 sha256=36dd469ce87fd2ffcc8165b7aa553c6ca78f2eae9ce4276e5ca609b58f7ee3df\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=721059fd4365fff58575d58990ad996b2545ee7893d8c9b9e8fc48755b32127e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill hdfs pyjsparser docopt\n",
            "Installing collected packages: pyjsparser, docopt, crcmod, zstandard, requests, redis, orjson, objsize, js2py, fasteners, fastavro, dnspython, dill, pymongo, hdfs, apache_beam\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache_beam-2.58.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.1 docopt-0.6.2 fastavro-1.9.7 fasteners-0.19 hdfs-2.7.3 js2py-0.74 objsize-0.7.0 orjson-3.10.7 pyjsparser-2.7.1 pymongo-4.8.0 redis-5.0.8 requests-2.31.0 zstandard-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install apache_beam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Simple Pipeline"
      ],
      "metadata": {
        "id": "iB3sgGj8Kw-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam"
      ],
      "metadata": {
        "id": "vrWrbGSByPIu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_perennial(plant):\n",
        "  return plant[\"duration\"] == \"perennial\"\n"
      ],
      "metadata": {
        "id": "IhNeAGQ6ys5l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  perennials = (\n",
        "      pipeline | \"Gardening plants\" >> beam.Create([\n",
        "          {\n",
        "              \"icon\": \"üçì\",\n",
        "              \"name\": \"Strawberry\",\n",
        "              \"duration\": \"perennial\"\n",
        "          },\n",
        "          {\n",
        "              \"icon\": \"ü•ï\",\n",
        "              \"name\": \"Carrot\",\n",
        "              \"duration\": \"biennial\"\n",
        "          },\n",
        "          {\n",
        "              \"icon\": \"üçÜ\",\n",
        "              \"name\": \"Eggplant\",\n",
        "              \"duration\": \"perennial\"\n",
        "          },\n",
        "          {\n",
        "              \"icon\": \"üçÖ\",\n",
        "              \"name\": \"Tomato\",\n",
        "              \"duration\": \"annual\"\n",
        "          },\n",
        "          {\n",
        "              \"icon\": \"ü•î\",\n",
        "              \"name\": \"Potato\",\n",
        "              \"duration\": \"perennial\"\n",
        "          },\n",
        "          ])\n",
        "      | \"Filter perennials\" >> beam.Filter(is_perennial)\n",
        "      | beam.Map(print)\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "2y82gyymzSiM",
        "outputId": "8d50e243-1694-4be7-9268-3c7fff769d76"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'icon': 'üçì', 'name': 'Strawberry', 'duration': 'perennial'}\n",
            "{'icon': 'üçÜ', 'name': 'Eggplant', 'duration': 'perennial'}\n",
            "{'icon': 'ü•î', 'name': 'Potato', 'duration': 'perennial'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_grocerystore(store):\n",
        "  return store[8] ==\"Grocery Store\"\n"
      ],
      "metadata": {
        "id": "GH2R4cuZ0GFW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p2 = beam.Pipeline()\n",
        "\n",
        "grocery = (p2\n",
        "           | \"Read from text\" >> beam.io.ReadFromText(\"/content/grocery.txt\", skip_header_lines=1)\n",
        "           | \"Split record\" >> beam.Map(lambda record: record.split(\",\"))\n",
        "           | \"Filter regular\" >> beam.Filter(is_grocerystore)\n",
        "           | \"Write to text\" >> beam.io.WriteToText(\"/content/regular_filter.txt\")\n",
        "           | \"Print\" >> beam.Map(print))\n",
        "p2.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMx9i55-0s5t",
        "outputId": "5a4cc1c0-69eb-4af2-e919-1076856a9d4b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/regular_filter.txt-00000-of-00001\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7cc46cb3eb30>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPv_Xa2R3HkB",
        "outputId": "183a8edf-bb4e-4232-bce8-4baef7b8a792"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grocery.txt  regular_filter.txt-00000-of-00001\tsample_data  students.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat regular_filter.txt-00000-of-00001"
      ],
      "metadata": {
        "id": "IkqcxHib4CFB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCollection in Apache Beam\n",
        "\n",
        "\n",
        "‚óè\tPCollection: It is an abstraction represents a potentially distributed, multi-element data set. It represents a distributed data set that our beam pipeline operates on.\n",
        "o\tImmutability: Pcollections are immutable in nature. Applying a transformations on a pcollection results in creation of new pcollection.\n",
        "o\tElement type: The elements in pcollection may be of any type, but all must be of same type.\n",
        "o\tOperation type:  Pcollection does not support grained operations. We cannot apply transformations on specific elements in pcollection.\n",
        "o\tTimestamps: Each element in pcollection has an associated timestamp with it.\n",
        "o\tUnbounded pcollections: An unbounded PCollection represents a data set of unlimited size. Source assigns the timestamps.\n",
        "o\tBounded pcollections: A bounded PCollection represents a data set of a known fixed size. Every element is set to same timestamp.\n",
        "o\tNo Random access: Can‚Äôt access data using index or some specific element. No size restriction.\n",
        "o\tPtransform: Ptransform represent a data processing operation, or a step in our pipeline. Ex., Map, Groupby, FlatMap, ParDo, filter, flatten, combine etc.\n",
        "\n",
        "‚óè\tPCollection characteristics:\n",
        "o\tA PCollection is owned by the specific Pipeline object for which it is created; multiple pipelines cannot share a PCollection.\n",
        "‚óè\tResources:\n",
        "o\thttps://beam.apache.org/documentation/programming-guide/#pcollections\n",
        "o\thttps://beam.apache.org/releases/pydoc/2.36.0/apache_beam.io.textio.html?highlight=readfromtext#apache_beam.io.textio.ReadFromText\n"
      ],
      "metadata": {
        "id": "csXKcba7K0yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1= beam.Pipeline()\n",
        "p1 | beam.io.ReadFromText(\"/content/grocery.txt\", skip_header_lines=1) | beam.Map(print)\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "-H5tdEyk4JXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6a0e77-9483-48cd-f37d-0859b4e73047"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FDA15,9.3,Low Fat,0.016047301,Dairy,249.8092,OUT049,1999,Medium,Tier 1,Supermarket Type1,3735.138\n",
            "DRC01,5.92,Regular,0.019278216,Soft Drinks,48.2692,OUT018,2009,Medium,Tier 3,Supermarket Type2,443.4228\n",
            "FDN15,17.5,Low Fat,0.016760075,Meat,141.618,OUT049,1999,Medium,Tier 1,Supermarket Type1,2097.27\n",
            "FDX07,19.2,Regular,0,Fruits and Vegetables,182.095,OUT010,1998,,Tier 3,Grocery Store,732.38\n",
            "NCD19,8.93,Low Fat,0,Household,53.8614,OUT013,1987,High,Tier 3,Supermarket Type1,994.7052\n",
            "FDP36,10.395,Regular,0,Baking Goods,51.4008,OUT018,2009,Medium,Tier 3,Supermarket Type2,556.6088\n",
            "FDO10,13.65,Regular,0.012741089,Snack Foods,57.6588,OUT013,1987,High,Tier 3,Supermarket Type1,343.5528\n",
            "FDP10,,Low Fat,0.127469857,Snack Foods,107.7622,OUT027,1985,Medium,Tier 3,Supermarket Type3,4022.7636\n",
            "FDH17,16.2,Regular,0.016687114,Frozen Foods,96.9726,OUT045,2002,,Tier 2,Supermarket Type1,1076.5986\n",
            "FDU28,19.2,Regular,0.09444959,Frozen Foods,187.8214,OUT017,2007,,Tier 2,Supermarket Type1,4710.535\n",
            "FDY07,11.8,Low Fat,0,Fruits and Vegetables,45.5402,OUT049,1999,Medium,Tier 1,Supermarket Type1,1516.0266\n",
            "FDA03,18.5,Regular,0.045463773,Dairy,144.1102,OUT046,1997,Small,Tier 1,Supermarket Type1,2187.153\n",
            "FDX32,15.1,Regular,0.1000135,Fruits and Vegetables,145.4786,OUT049,1999,Medium,Tier 1,Supermarket Type1,1589.2646\n",
            "FDS46,17.6,Regular,0.047257328,Snack Foods,119.6782,OUT046,1997,Small,Tier 1,Supermarket Type1,2145.2076\n",
            "FDF32,16.35,Low Fat,0.0680243,Fruits and Vegetables,196.4426,OUT013,1987,High,Tier 3,Supermarket Type1,1977.426\n",
            "FDP49,9,Regular,0.069088961,Breakfast,56.3614,OUT046,1997,Small,Tier 1,Supermarket Type1,1547.3192\n",
            "NCB42,11.8,Low Fat,0.008596051,Health and Hygiene,115.3492,OUT018,2009,Medium,Tier 3,Supermarket Type2,1621.8888\n",
            "FDP49,9,Regular,0.069196376,Breakfast,54.3614,OUT049,1999,Medium,Tier 1,Supermarket Type1,718.3982\n",
            "DRI11,,Low Fat,0.034237682,Hard Drinks,113.2834,OUT027,1985,Medium,Tier 3,Supermarket Type3,2303.668\n",
            "FDU02,13.35,Low Fat,0.10249212,Dairy,230.5352,OUT035,2004,Small,Tier 2,Supermarket Type1,2748.4224\n",
            "FDN22,18.85,Regular,0.138190277,Snack Foods,250.8724,OUT013,1987,High,Tier 3,Supermarket Type1,3775.086\n",
            "FDW12,,Regular,0.035399923,Baking Goods,144.5444,OUT027,1985,Medium,Tier 3,Supermarket Type3,4064.0432\n",
            "NCB30,14.6,Low Fat,0.025698134,Household,196.5084,OUT035,2004,Small,Tier 2,Supermarket Type1,1587.2672\n",
            "FDC37,,Low Fat,0.057556998,Baking Goods,107.6938,OUT019,1985,Small,Tier 1,Grocery Store,214.3876\n",
            "FDR28,13.85,Regular,0.025896485,Frozen Foods,165.021,OUT046,1997,Small,Tier 1,Supermarket Type1,4078.025\n",
            "NCD06,13,Low Fat,0.099887103,Household,45.906,OUT017,2007,,Tier 2,Supermarket Type1,838.908\n",
            "FDV10,7.645,Regular,0.066693437,Snack Foods,42.3112,OUT035,2004,Small,Tier 2,Supermarket Type1,1065.28\n",
            "DRJ59,11.65,low fat,0.019356132,Hard Drinks,39.1164,OUT013,1987,High,Tier 3,Supermarket Type1,308.9312\n",
            "FDE51,5.925,Regular,0.161466534,Dairy,45.5086,OUT010,1998,,Tier 3,Grocery Store,178.4344\n",
            "FDC14,,Regular,0.072221801,Canned,43.6454,OUT019,1985,Small,Tier 1,Grocery Store,125.8362\n",
            "FDV38,19.25,Low Fat,0.170348551,Dairy,55.7956,OUT010,1998,,Tier 3,Grocery Store,163.7868\n",
            "NCS17,18.6,Low Fat,0.080829372,Health and Hygiene,96.4436,OUT018,2009,Medium,Tier 3,Supermarket Type2,2741.7644\n",
            "FDP33,18.7,Low Fat,0,Snack Foods,256.6672,OUT018,2009,Medium,Tier 3,Supermarket Type2,3068.0064\n",
            "FDO23,17.85,Low Fat,0,Breads,93.1436,OUT045,2002,,Tier 2,Supermarket Type1,2174.5028\n",
            "DRH01,17.5,Low Fat,0.097904029,Soft Drinks,174.8738,OUT046,1997,Small,Tier 1,Supermarket Type1,2085.2856\n",
            "NCX29,10,Low Fat,0.089291137,Health and Hygiene,146.7102,OUT049,1999,Medium,Tier 1,Supermarket Type1,3791.0652\n",
            "FDV20,,Regular,0.059511812,Fruits and Vegetables,128.0678,OUT027,1985,Medium,Tier 3,Supermarket Type3,2797.6916\n",
            "DRZ11,8.85,Regular,0.113123893,Soft Drinks,122.5388,OUT018,2009,Medium,Tier 3,Supermarket Type2,1609.9044\n",
            "FDX10,,Regular,0.123111453,Snack Foods,36.9874,OUT027,1985,Medium,Tier 3,Supermarket Type3,388.1614\n",
            "FDB34,,Low Fat,0.026480954,Snack Foods,87.6198,OUT027,1985,Medium,Tier 3,Supermarket Type3,2180.495\n",
            "FDU02,13.35,Low Fat,0.102511504,Dairy,230.6352,OUT046,1997,Small,Tier 1,Supermarket Type1,3435.528\n",
            "FDK43,9.8,Low Fat,0.02681843,Meat,126.002,OUT013,1987,High,Tier 3,Supermarket Type1,2150.534\n",
            "FDA46,13.6,Low Fat,0.117818348,Snack Foods,192.9136,OUT049,1999,Medium,Tier 1,Supermarket Type1,2527.3768\n",
            "FDC02,21.35,Low Fat,0.069102831,Canned,259.9278,OUT018,2009,Medium,Tier 3,Supermarket Type2,6768.5228\n",
            "FDL50,12.15,Regular,0.042277867,Canned,126.5046,OUT013,1987,High,Tier 3,Supermarket Type1,373.5138\n",
            "FDM39,6.42,LF,0.089498926,Dairy,178.1002,OUT010,1998,,Tier 3,Grocery Store,358.2004\n",
            "NCP05,19.6,Low Fat,0,Health and Hygiene,153.3024,OUT045,2002,,Tier 2,Supermarket Type1,2428.8384\n",
            "FDV49,10,Low Fat,0.025879577,Canned,265.2226,OUT045,2002,,Tier 2,Supermarket Type1,5815.0972\n",
            "FDL12,15.85,Regular,0.121632721,Baking Goods,60.622,OUT046,1997,Small,Tier 1,Supermarket Type1,2576.646\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7cc46e1adc60>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p2= beam.Pipeline()\n",
        "grocery = (p2\n",
        "    | \"Read from  text\" >> beam.io.ReadFromText(\"/content/grocery.txt\", skip_header_lines=1)\n",
        "    # | beam.Map(lambda record: print(record))\n",
        "    | \"Split the record\" >> beam.Map(lambda record: record.split(\",\"))\n",
        "    # | 'Filter regular' >> beam.Filter(lambda record: record[2]=='Regular')\n",
        "    | 'Filter regular' >> beam.Filter(lambda record: record[2]=='Low Fat')\n",
        "    | 'Write to text' >> beam.io.WriteToText('lowfat_filter2.txt')\n",
        "    | beam.Map(print)\n",
        "    )\n",
        "p2.run()"
      ],
      "metadata": {
        "id": "4i1fNBpaNHpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d46351-27c9-4885-cc40-ddd8bc8aba23"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lowfat_filter2.txt-00000-of-00001\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7cc46cb0a560>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "NnhuHtQoOUNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e640fc5f-1309-4e51-ea24-327beb7c1b6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grocery.txt\t\t\t   regular_filter.txt-00000-of-00001  students.txt\n",
            "lowfat_filter2.txt-00000-of-00001  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat regular_filter1.txt-00000-of-00001"
      ],
      "metadata": {
        "id": "g-xwMGDHOppA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada35f51-ab36-4bbb-ef65-4195e8cf0cc5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: regular_filter1.txt-00000-of-00001: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from external resources\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "grocery = (p1\n",
        "           | \"Read from Text\" >> beam.io.ReadFromText(\"grocery.txt\", skip_header_lines=1)\n",
        "           | \"split the record\" >> beam.Map(lambda record: record.split(','))\n",
        "           | 'Filter regular' >> beam.Filter(lambda record: record[2] == 'Regular')\n",
        "           | 'Write to text'>> beam.io.WriteToText('regular_filter.txt'))  #| beam.Map(print))\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QlHUk4NOr5Q",
        "outputId": "138dd0b6-34cd-40bb-c0ec-b4de01b7a611"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7cc46c970b80>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p3 = beam.Pipeline()\n",
        "lines = (p3\n",
        "         | beam.Create([\n",
        "             \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. \",\n",
        "             \"Phasellus maximus laoreet nunc ut euismod. Duis elit dolor, \",\n",
        "             \"Donec a ligula dapibus, dignissim est sit amet, cursus augue.\",\n",
        "             \"Phasellus dapibus, odio non faucibus interdum\",\n",
        "             \"Sed mattis arcu sed auctor sodales. Nulla facilisi.\"\n",
        "             ])\n",
        "        #  | beam.Map(print)\n",
        "         | beam.io.WriteToText(\"testcreate.txt\"))"
      ],
      "metadata": {
        "id": "s_uALrwrRb9p"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p3.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lySRDivXTPTZ",
        "outputId": "6910bdf2-e7c1-4164-988b-4aa053b6afbc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7cc46c90bc40>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p4 = beam.Pipeline()\n",
        "lines = (p4\n",
        "         | beam.Create([\n",
        "             \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. \",\n",
        "             \"Phasellus maximus laoreet nunc ut euismod. Duis elit dolor, \",\n",
        "             \"Donec a ligula dapibus, dignissim est sit amet, cursus augue.\",\n",
        "             \"Phasellus dapibus, odio non faucibus interdum\",\n",
        "             \"Sed mattis arcu sed auctor sodales. Nulla facilisi.\"\n",
        "             ])\n",
        "        #  | beam.Map(print)\n",
        "         | beam.io.WriteToText(\"testcreate.txt\"))\n",
        "p4.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN1y_0QLTWo_",
        "outputId": "f67f97cf-9199-408a-aa4f-cc0e4d1d1d4a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7cc46c934040>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  lines = (pipeline\n",
        "           | beam.Create([\n",
        "               \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. \",\n",
        "               \"Phasellus maximus laoreet nunc ut euismod. Duis elit dolor, \",\n",
        "               \"Donec a ligula dapibus, dignissim est sit amet, cursus augue.\",\n",
        "               \"Sed mattis arcu sed auctor sodales. Nulla facilisi.\"\n",
        "           ])\n",
        "           | beam.Map(print))\n",
        "  pipeline.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dePbMKGiUDQ3",
        "outputId": "b7c79b14-72d3-43fa-85f3-04df4fd31459"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lorem ipsum dolor sit amet, consectetur adipiscing elit. \n",
            "Phasellus maximus laoreet nunc ut euismod. Duis elit dolor, \n",
            "Donec a ligula dapibus, dignissim est sit amet, cursus augue.\n",
            "Sed mattis arcu sed auctor sodales. Nulla facilisi.\n",
            "Lorem ipsum dolor sit amet, consectetur adipiscing elit. \n",
            "Phasellus maximus laoreet nunc ut euismod. Duis elit dolor, \n",
            "Donec a ligula dapibus, dignissim est sit amet, cursus augue.\n",
            "Sed mattis arcu sed auctor sodales. Nulla facilisi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map, FlatMap and Filter Transforms in Apache Beam\n",
        "\n",
        "\n",
        "Map:\n",
        "‚óè\tApplies a simple 1-to-1 mapping function over each element in the collection.\n",
        "FlatMap:\n",
        "‚óè\tApplies a simple 1-to-many mapping function over each element in the collection. The many elements are flattened into the resulting collection.\n",
        "Filter:\n",
        "‚óè\tGiven a predicate, filter out all elements that don‚Äôt satisfy that predicate. May also be used to filter based on an inequality with a given value based on the comparison ordering of the element.\n",
        "Lambda:\n",
        "‚óè\tA lambda function is a small anonymous function. A lambda function can take any number of arguments, but can only have one expression.\n",
        "o\tlambda arguments: expression\n",
        "Resources:\n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/elementwise/map/\n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/elementwise/flatmap/  \n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/elementwise/filter/#example-2-filtering-with-a-lambda-function\n"
      ],
      "metadata": {
        "id": "d8KyghmoFWkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVmRwZYCFQNk",
        "outputId": "28e0a73a-d23b-42ac-b4fb-de90ba2c9a03"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grocery.txt\t\t\t   regular_filter.txt-00000-of-00001  students.txt\n",
            "lowfat_filter2.txt-00000-of-00001  sample_data\t\t\t      testcreate.txt-00000-of-00001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map:\n",
        "\n",
        "‚óè Applies a simple 1-to-1 mapping function over each element in the collection."
      ],
      "metadata": {
        "id": "VSdCryZ-HqmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_header_and_newline(text):\n",
        "  return text.strip('# \\n')\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  plants = (\n",
        "      pipeline\n",
        "      | 'Gardening plants' >> beam.Create([\n",
        "          '# üçìStrawberry\\n',\n",
        "          '# ü•ïCarrot\\n',\n",
        "          '# üçÜEggplant\\n',\n",
        "          '# üçÖTomato\\n',\n",
        "          '# ü•îPotato\\n',\n",
        "      ])\n",
        "      | 'Strip header' >> beam.Map(strip_header_and_newline)\n",
        "      | beam.Map(type)\n",
        "      # | beam.Filter(lambda record: \"berry\" in record)\n",
        "      # | beam.Map(len)\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erymGDP6Ho-t",
        "outputId": "3d55a8d7-db91-41ed-b521-8dc09f60e04a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "FlatMap\n",
        "\n",
        "\n",
        "‚Ä¢ Applies a simple 1-to-many mapping function over each element in the collection. The many elements are flattened into the resulting collection."
      ],
      "metadata": {
        "id": "J3GHk4cGIWOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_words(text):\n",
        "  return text.split(',')\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  plants = (\n",
        "      pipeline\n",
        "      | 'Gardening plants' >> beam.Create([\n",
        "          'üçìStrawberry,ü•ïCarrot,üçÜEggplant',\n",
        "          'üçÖTomato,ü•îPotato',\n",
        "      ])\n",
        "      | 'Split words' >> beam.FlatMap(split_words)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFMyJU9GIPl3",
        "outputId": "1a592515-34b1-4326-9cef-c955a6dc0c78"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üçìStrawberry\n",
            "ü•ïCarrot\n",
            "üçÜEggplant\n",
            "üçÖTomato\n",
            "ü•îPotato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "FlatMapTuple for key-value pairs\n",
        "\n",
        "If your PCollection consists of (key, value) pairs, you can use FlatMapTuple to unpack them into different function arguments.\n"
      ],
      "metadata": {
        "id": "2yJ_u5I3LRpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def format_plant(icon, plant):\n",
        "  if icon:\n",
        "    yield '{}{}'.format(icon, plant)\n",
        "\n",
        "# def format_plant(record):\n",
        "#   if record[0]:\n",
        "#     yield '{}{}'.format(record[0], record[1])\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  plants = (\n",
        "      pipeline\n",
        "      | 'Gardening plants' >> beam.Create([\n",
        "          ('üçì', 'Strawberry'),\n",
        "          ('ü•ï', 'Carrot'),\n",
        "          ('üçÜ', 'Eggplant'),\n",
        "          ('üçÖ', 'Tomato'),\n",
        "          ('ü•î', 'Potato'),\n",
        "          (None, 'Invalid'),\n",
        "      ])\n",
        "      | 'Format' >> beam.FlatMapTuple(format_plant)\n",
        "      # | 'Format' >> beam.FlatMap(format_plant)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_6PPVU5LUie",
        "outputId": "80afb762-db10-4b6f-ab17-455d61dd71e7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üçìStrawberry\n",
            "ü•ïCarrot\n",
            "üçÜEggplant\n",
            "üçÖTomato\n",
            "ü•îPotato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Filter\n",
        "\n",
        "Given a predicate, filter out all elements that don‚Äôt satisfy that predicate. May also be used to filter based on an inequality with a given value based on the comparison ordering of the element.\n"
      ],
      "metadata": {
        "id": "_tfpjpaFMFvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_perennial(plant):\n",
        "  return plant['duration'] == 'perennial'\n",
        "\n",
        "def filter_icon(record):\n",
        "  return record[\"icon\"] == 'üçì'\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  perennials = (\n",
        "      pipeline\n",
        "      | 'Gardening plants' >> beam.Create([\n",
        "          {\n",
        "              'icon': 'üçì', 'name': 'Strawberry', 'duration': 'perennial'\n",
        "          },\n",
        "          {\n",
        "              'icon': 'ü•ï', 'name': 'Carrot', 'duration': 'biennial'\n",
        "          },\n",
        "          {\n",
        "              'icon': 'üçÜ', 'name': 'Eggplant', 'duration': 'perennial'\n",
        "          },\n",
        "          {\n",
        "              'icon': 'üçÖ', 'name': 'Tomato', 'duration': 'annual'\n",
        "          },\n",
        "          {\n",
        "              'icon': 'ü•î', 'name': 'Potato', 'duration': 'perennial'\n",
        "          },\n",
        "      ])\n",
        "      # | 'Filter perennials' >> beam.Filter(is_perennial)\n",
        "      | 'Filter strawberry icon' >> beam.Filter(filter_icon)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFp_yAZBMJx8",
        "outputId": "a0c5b7fc-10a4-4bf3-f17b-477635767f95"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'icon': 'üçì', 'name': 'Strawberry', 'duration': 'perennial'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Filtering with multiple arguments\n",
        "\n",
        "def has_duration(plant, duration):\n",
        "  return plant['duration'] == duration\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  perennials = (\n",
        "      pipeline\n",
        "      | 'Gardening plants' >> beam.Create([\n",
        "          {\n",
        "              'icon': 'üçì', 'name': 'Strawberry', 'duration': 'perennial'\n",
        "          },\n",
        "          {\n",
        "              'icon': 'ü•ï', 'name': 'Carrot', 'duration': 'biennial'\n",
        "          },\n",
        "          {\n",
        "              'icon': 'üçÜ', 'name': 'Eggplant', 'duration': 'perennial'\n",
        "          },\n",
        "          {\n",
        "              'icon': 'üçÖ', 'name': 'Tomato', 'duration': 'annual'\n",
        "          },\n",
        "          {\n",
        "              'icon': 'ü•î', 'name': 'Potato', 'duration': 'perennial'\n",
        "          },\n",
        "      ])\n",
        "      | 'Filter annual' >> beam.Filter(has_duration, 'annual')\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXPNoJ1WM9Bn",
        "outputId": "46cd55ee-6021-48cc-dbd2-2db7e9a3c9bd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'icon': 'üçÖ', 'name': 'Tomato', 'duration': 'annual'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  students = (\n",
        "      pipeline\n",
        "      |\"Read from text\" >> beam.io.ReadFromText(\"students.txt\", skip_header_lines= True)\n",
        "      |\"spliting the record\" >> beam.Map(lambda record : record.split(','))\n",
        "      |\"filtering the data with PASS\" >> beam.Filter(lambda record : record[5]==\"PASS\")\n",
        "      |\"Write to text\" >> beam.io.WriteToText(\"result/pass_students\")\n",
        "  )\n"
      ],
      "metadata": {
        "id": "4pydqukcNeFP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpQFR95_Nmac",
        "outputId": "e9275506-04aa-40de-fd24-99a1841bf65f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grocery.txt\t\t\t   result\t testcreate.txt-00000-of-00001\n",
            "lowfat_filter2.txt-00000-of-00001  sample_data\n",
            "regular_filter.txt-00000-of-00001  students.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 result/pass_students-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEXGbr9tNo2e",
        "outputId": "c8966ee5-383b-4e56-8a9e-becf31f65da0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['3', 'chandler', 'us', '53', '68', 'PASS']\n",
            "['4', 'khaula', 'hyd', '26', '99', 'PASS']\n",
            "['5', 'neethu', 'uae', '27', '100', 'PASS']\n",
            "['7', 'sai', 'mad', '21', '71', 'PASS']\n",
            "['8', 'sabari', 'vel', '25', '75', 'PASS']\n",
            "['10', 'swati', 'ind', '24', '91', 'PASS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ParDo, Keys, kvswap, Values, ToString Transforms in Apache Beam"
      ],
      "metadata": {
        "id": "KEPW1seAViPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normal way using Tranformation functions"
      ],
      "metadata": {
        "id": "wWTpYs567Yie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#implementation using normal tranformations\n",
        "with beam.Pipeline() as pipeline:\n",
        "  students = (\n",
        "      pipeline\n",
        "      | \"Read from text\" >> beam.io.ReadFromText(\"/content/students.txt\", skip_header_lines=True)\n",
        "      | \"Splitting the records\" >> beam.Map(lambda record: record.split(\",\"))\n",
        "      | \"Filtering the data with Fail\" >> beam.Filter(lambda record: record[5]==\"FAIL\")\n",
        "      | \"Write to text\">> beam.io.WriteToText(\"result/fail_students\")\n",
        "  )\n",
        "  pipeline.run()"
      ],
      "metadata": {
        "id": "ZjPoTGv1VY6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20272d53-4f19-48a3-fa43-c6a478925ace"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{(\"head -n 10 /content/result/fail_students-00000-of-00001\")}"
      ],
      "metadata": {
        "id": "2FaOdZynUosw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1804351d-e7ea-4e2b-bb5f-e2042be18834"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', 'vignesh', 'chn', '27', '15', 'FAIL']\n",
            "['2', 'joey', 'us', '51', '20', 'FAIL']\n",
            "['6', 'sree', 'koc', '25', '27', 'FAIL']\n",
            "['9', 'tinkle', 'ker', '27', '9', 'FAIL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using ParDo"
      ],
      "metadata": {
        "id": "ZDAfiJLM7e_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitRow(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    return [element.split(\",\")]\n",
        "\n",
        "class ComputeWordLengthFn(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    return [len(element)]"
      ],
      "metadata": {
        "id": "uiT-Y3Nw7Ki0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  input_data = (pipeline\n",
        "                | \"Read from text\" >> beam.io.ReadFromText(\"/content/students.txt\", skip_header_lines=True)\n",
        "                | \"Splitting the record\" >> beam.ParDo(SplitRow()))\n",
        "  data_fail = (input_data\n",
        "               | \"Filter data with fail\" >> beam.Filter(lambda record: record[5]==\"FAIL\"))\n",
        "  word_lengths = (data_fail\n",
        "                  | \"Count of Record\" >> beam.ParDo(ComputeWordLengthFn()))\n",
        "  counted_data = (word_lengths\n",
        "                  | \"Write counted data to text\" >> beam.io.WriteToText(\"result/data_fail\"))\n",
        "  output_data = (counted_data\n",
        "                 | \"Write to Text\" >> beam.io.WriteToText(\"result/fail_data\"))\n",
        "  pipeline.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJiNaZiz74Hj",
        "outputId": "24c2aea9-6220-4173-ddd8-f23348f1cae0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{(\"head -n 10 /content/result/data_fail-00000-of-00001\")}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L3m72Ye-8uC",
        "outputId": "546b886f-fabf-4434-980b-09c2ba34651d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "6\n",
            "6\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keys\n",
        "\n",
        "Takes a collection of key-value pairs and returns the key of each element."
      ],
      "metadata": {
        "id": "qo7Fz8-1_nvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  icons = (\n",
        "      pipeline\n",
        "      | 'Garden plants' >> beam.Create([\n",
        "          ('üçì', 'Strawberry'),\n",
        "          ('ü•ï', 'Carrot'),\n",
        "          ('üçÜ', 'Eggplant'),\n",
        "          ('üçÖ', 'Tomato'),\n",
        "          ('ü•î', 'Potato'),\n",
        "      ])\n",
        "      | 'Keys' >> beam.Keys()\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxuGboqN_cRe",
        "outputId": "78f15754-8c5f-4c1c-d1de-c019e6618fbd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üçì\n",
            "ü•ï\n",
            "üçÜ\n",
            "üçÖ\n",
            "ü•î\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values\n",
        "\n",
        "Takes a collection of key-value pairs, and returns the value of each element."
      ],
      "metadata": {
        "id": "tdf3YhhdAahe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  icons = (\n",
        "      pipeline\n",
        "      | 'Garden plants' >> beam.Create([\n",
        "          ('üçì', 'Strawberry'),\n",
        "          ('ü•ï', 'Carrot'),\n",
        "          ('üçÜ', 'Eggplant'),\n",
        "          ('üçÖ', 'Tomato'),\n",
        "          ('ü•î', 'Potato'),\n",
        "      ])\n",
        "      | 'Keys' >> beam.Values()\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXyjdoJ0AMyn",
        "outputId": "99830957-1418-4e03-ec60-6a4e8866f32f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strawberry\n",
            "Carrot\n",
            "Eggplant\n",
            "Tomato\n",
            "Potato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ToString\n",
        "\n",
        "Transforms every element in an input collection to a string. Any non-string element can be converted to a string using standard Python functions and methods. Many I/O transforms, such as textio.WriteToText, expect their input elements to be strings.\n",
        "\n",
        "    Key-value pairs to string\n",
        "    Elements to string\n",
        "    Iterables to string\n"
      ],
      "metadata": {
        "id": "nDbFMcHsAfMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  plants = (\n",
        "      pipeline\n",
        "      | 'Garden plants' >> beam.Create([\n",
        "          ('üçì', 'Strawberry'),\n",
        "          ('ü•ï', 'Carrot'),\n",
        "          ('üçÜ', 'Eggplant'),\n",
        "          ('üçÖ', 'Tomato'),\n",
        "          ('ü•î', 'Potato'),\n",
        "      ])\n",
        "      | 'To string' >> beam.ToString.Kvs()  #Element() #Iterables()\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAZs3Zn3AZam",
        "outputId": "0e28476b-c182-4040-dd66-1df083b3497f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üçì,Strawberry\n",
            "ü•ï,Carrot\n",
            "üçÜ,Eggplant\n",
            "üçÖ,Tomato\n",
            "ü•î,Potato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  plants = (\n",
        "      pipeline\n",
        "      | 'Garden plants' >> beam.Create([\n",
        "          ('üçì', 'Strawberry'),\n",
        "          ('ü•ï', 'Carrot'),\n",
        "          ('üçÜ', 'Eggplant'),\n",
        "          ('üçÖ', 'Tomato'),\n",
        "          ('ü•î', 'Potato'),\n",
        "      ])\n",
        "      | 'To string' >> beam.ToString.Element() #Iterables()\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqRb9A4zAuM4",
        "outputId": "2fa2a8d4-ba99-4b4a-a792-3022de97c7c7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('üçì', 'Strawberry')\n",
            "('ü•ï', 'Carrot')\n",
            "('üçÜ', 'Eggplant')\n",
            "('üçÖ', 'Tomato')\n",
            "('ü•î', 'Potato')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  plants = (\n",
        "      pipeline\n",
        "      | 'Garden plants' >> beam.Create([\n",
        "          ('üçì', 'Strawberry'),\n",
        "          ('ü•ï', 'Carrot'),\n",
        "          ('üçÜ', 'Eggplant'),\n",
        "          ('üçÖ', 'Tomato'),\n",
        "          ('ü•î', 'Potato'),\n",
        "      ])\n",
        "      | 'To string' >> beam.ToString.Iterables()\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puxSQ_b0BDrV",
        "outputId": "cd00ffd7-fd1d-47ff-b5ff-3da365b4a68a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üçì,Strawberry\n",
            "ü•ï,Carrot\n",
            "üçÜ,Eggplant\n",
            "üçÖ,Tomato\n",
            "ü•î,Potato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kvswap\n",
        "\n",
        "Takes a collection of key-value pairs and returns a collection of key-value pairs which has each key and value swapped."
      ],
      "metadata": {
        "id": "Eay8YL06BQqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  plants = (\n",
        "      pipeline\n",
        "      | 'Garden plants' >> beam.Create([\n",
        "          ('üçì', 'Strawberry'),\n",
        "          ('ü•ï', 'Carrot'),\n",
        "          ('üçÜ', 'Eggplant'),\n",
        "          ('üçÖ', 'Tomato'),\n",
        "          ('ü•î', 'Potato'),\n",
        "      ])\n",
        "      | 'Key-Value swap' >> beam.KvSwap()\n",
        "      | \"Keys\" >> beam.Keys()\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLEQl_zSBGAn",
        "outputId": "59ba6828-22b8-4162-df57-6bbc60809c9b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strawberry\n",
            "Carrot\n",
            "Eggplant\n",
            "Tomato\n",
            "Potato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  plants = (\n",
        "      pipeline\n",
        "      | 'Garden plants' >> beam.Create([\n",
        "          ('üçì', 'Strawberry'),\n",
        "          ('ü•ï', 'Carrot'),\n",
        "          ('üçÜ', 'Eggplant'),\n",
        "          ('üçÖ', 'Tomato'),\n",
        "          ('ü•î', 'Potato'),\n",
        "      ])\n",
        "      | 'Key-Value swap' >> beam.KvSwap()\n",
        "      | \"Keys\" >> beam.Values()\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOh05gLGBZhG",
        "outputId": "b5e20447-583f-435c-8a53-dbb11e0c6c1b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üçì\n",
            "ü•ï\n",
            "üçÜ\n",
            "üçÖ\n",
            "ü•î\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1SIZ3zQgBwZN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TcnN4z4pBk0p"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7xN6LFQyQaGh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GroupBy(), GroupByKey(), CoGroupByKey(), GroupIntoBatches() Transforms in Apache Beam\n",
        "\n",
        "\n",
        "GroupBy:\n",
        "‚óè\tTakes a collection of elements and produces a collection grouped, by properties of those elements.\n",
        "\n",
        "‚óè\tUnlike GroupByKey, the key is dynamically created from the elements themselves.\n",
        "GroupByKey:\n",
        "\n",
        "‚óè\tGroupByKey is a Beam transform for processing collections of key/value pairs.\n",
        "\n",
        "‚óè\tTakes a keyed collection of elements and produces a collection where each element consists of a key and all values associated with that key.\n",
        "\n",
        "‚óè\tIt‚Äôs a parallel reduction operation, analogous to the Shuffle phase of a Map/Shuffle/Reduce-style algorithm.\n",
        "\n",
        "‚óè\tFor example, if you have a collection that stores records of customer orders, you might want to group together all the orders from the same postal code (wherein the ‚Äúkey‚Äù of the key/value pair is the postal code field, and the ‚Äúvalue‚Äù is the remainder of the record).\n",
        "\n",
        "\n",
        "CoGroupByKey:\n",
        "\n",
        "‚óè\tAggregates all input elements by their key and allows downstream processing to consume all values associated with the key.\n",
        "\n",
        "‚óè\tWhile GroupByKey performs this operation over a single input collection and thus a single type of input values, CoGroupByKey operates over multiple input collections.\n",
        "\n",
        "‚óè\tCoGroupByKey expects a dictionary of named keyed PCollections, and produces elements joined by their keys. The values of each output element are dictionaries where the names correspond to the input dictionary, with lists of all the values found for that key.\n",
        "\n",
        "‚óè\tAs a result, the result for each key is a tuple of the values associated with that key in each input collection.\n",
        "GroupIntoBatches:\n",
        "\n",
        "‚óè\tBatches the input into desired batch size.\n",
        "\n",
        "\n",
        "Resources:\n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/aggregation/groupby/\n",
        "‚óè\thttps://beam.apache.org/documentation/programming-guide/#groupbykey\n",
        "o\thttps://beam.apache.org/documentation/transforms/python/aggregation/groupbykey/\n"
      ],
      "metadata": {
        "id": "MpXTcKQwQbER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "GroupBy:\n",
        "\n",
        "  Takes a collection of elements and produces a collection grouped, by properties of those elements.\n",
        "  Unlike GroupByKey, the key is dynamically created from the elements themselves.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZjP5L_rWQx6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#groups based on first character of record\n",
        "with beam.Pipeline() as p:\n",
        "  grouped = (\n",
        "      p\n",
        "      | beam.Create(['strawberry', 'raspberry', 'blueberry', 'blackberry', 'banana'])\n",
        "      | beam.GroupBy(lambda s: s[0])\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GBvmBYYQp6s",
        "outputId": "167d80d8-9b67-453e-fa2e-ae76b586df04"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('s', ['strawberry'])\n",
            "('r', ['raspberry'])\n",
            "('b', ['blueberry', 'blackberry', 'banana'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregation:"
      ],
      "metadata": {
        "id": "4XU6xCSyTLiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GROCERY_LIST = [\n",
        "    beam.Row(recipe='pie', fruit='strawberry', quantity=3, unit_price=1.50),\n",
        "    beam.Row(recipe='pie', fruit='raspberry', quantity=1, unit_price=3.50),\n",
        "    beam.Row(recipe='pie', fruit='blackberry', quantity=1, unit_price=4.00),\n",
        "    beam.Row(recipe='pie', fruit='blueberry', quantity=1, unit_price=2.00),\n",
        "    beam.Row(recipe='muffin', fruit='blueberry', quantity=2, unit_price=2.00),\n",
        "    beam.Row(recipe='muffin', fruit='banana', quantity=3, unit_price=1.00),\n",
        "]\n"
      ],
      "metadata": {
        "id": "iTDMRtZERC-4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as p:\n",
        "  grouped = (p\n",
        "    | beam.Create(GROCERY_LIST)\n",
        "    | beam.GroupBy('recipe')\n",
        "    | beam.Map(print)\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETgkd1qxTPP7",
        "outputId": "a3341917-4401-4165-825e-194ae56de9cb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('pie', [BeamSchema_2aa0b8e0_c78d_4515_b6c8_0114ecc95a50(recipe='pie', fruit='strawberry', quantity=3, unit_price=1.5), BeamSchema_2aa0b8e0_c78d_4515_b6c8_0114ecc95a50(recipe='pie', fruit='raspberry', quantity=1, unit_price=3.5), BeamSchema_2aa0b8e0_c78d_4515_b6c8_0114ecc95a50(recipe='pie', fruit='blackberry', quantity=1, unit_price=4.0), BeamSchema_2aa0b8e0_c78d_4515_b6c8_0114ecc95a50(recipe='pie', fruit='blueberry', quantity=1, unit_price=2.0)])\n",
            "('muffin', [BeamSchema_2aa0b8e0_c78d_4515_b6c8_0114ecc95a50(recipe='muffin', fruit='blueberry', quantity=2, unit_price=2.0), BeamSchema_2aa0b8e0_c78d_4515_b6c8_0114ecc95a50(recipe='muffin', fruit='banana', quantity=3, unit_price=1.0)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sum aggregation function\n",
        "with beam.Pipeline() as p:\n",
        "  grouped = (\n",
        "      p\n",
        "      | beam.Create(GROCERY_LIST)\n",
        "      | beam.GroupBy('fruit')\n",
        "          .aggregate_field('quantity', sum, 'total_quantity')\n",
        "          | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh35FHSgTQLM",
        "outputId": "2d256ecf-ef25-44ba-b32a-c534cf660948"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result(fruit='strawberry', total_quantity=3)\n",
            "Result(fruit='raspberry', total_quantity=1)\n",
            "Result(fruit='blackberry', total_quantity=1)\n",
            "Result(fruit='blueberry', total_quantity=3)\n",
            "Result(fruit='banana', total_quantity=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with beam.Pipeline() as p:\n",
        "  grouped = (\n",
        "      p\n",
        "      | beam.Create(GROCERY_LIST)\n",
        "      | beam.GroupBy('recipe')\n",
        "          .aggregate_field('quantity', sum, 'total_quantity')\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gABQkB1UTkN",
        "outputId": "023c14b2-a233-4fd7-b676-2b242a612dea"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result(recipe='pie', total_quantity=6)\n",
            "Result(recipe='muffin', total_quantity=5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "GroupByKey:\n",
        "\n",
        "  Takes a keyed collection of elements and produces a collection where each element consists of a key and all values associated with that key.\n",
        "\n"
      ],
      "metadata": {
        "id": "UiC3iDC0VH2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records = [(\"vignesh\", [27, \"engineer\"]),\n",
        "(\"neethu\", [27, \"developer\"]),\n",
        "(\"farooqui\", [26, \"data analyst\"]),\n",
        "(\"sai\", [29, \"web developer\"]),\n",
        "(\"tinkle\", [28, \"fullstack developer\"]),\n",
        "(\"neethu\", 'Employed'),\n",
        "(\"sai\", 'Unemployed'),\n",
        "(\"tinkle\", 'Employed'),\n",
        "(\"farooqui\",'Employed'),\n",
        "(\"vignesh\", 'Unemployed')]"
      ],
      "metadata": {
        "id": "Vgn1HhDRU_ht"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  produce_counts = (\n",
        "      pipeline\n",
        "      | 'Create produce counts' >> beam.Create(records)\n",
        "      | 'Group counts per produce' >> beam.GroupByKey()\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzhCEHE7WEAe",
        "outputId": "67be6506-c7e4-4da7-9ac2-e72e704fce06"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('vignesh', [[27, 'engineer'], 'Unemployed'])\n",
            "('neethu', [[27, 'developer'], 'Employed'])\n",
            "('farooqui', [[26, 'data analyst'], 'Employed'])\n",
            "('sai', [[29, 'web developer'], 'Unemployed'])\n",
            "('tinkle', [[28, 'fullstack developer'], 'Employed'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "CoGroupByKey:\n",
        "\n",
        "  Aggregates all input elements by their key and allows downstream processing to consume all values associated with the key.\n",
        "  \n",
        "  While GroupByKey performs this operation over a single input collection and thus a single type of input values.\n",
        "  \n",
        "  CoGroupByKey operates over multiple input collections. As a result, the result for each key is a tuple of the values associated with that key in each input collection.\n",
        "\n"
      ],
      "metadata": {
        "id": "bFmJsf0OWpfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  student_pairs = pipeline | 'Create icons' >> beam.Create([\n",
        "      ('vignesh', 'bangalore'),\n",
        "      ('khaula', 'hyderabad'),\n",
        "      ('neethu', 'malapur'),\n",
        "      ('sai', 'chennai'),\n",
        "  ])\n",
        "\n",
        "  student_result = pipeline | 'Create durations' >> beam.Create([\n",
        "      ('vignesh', [15,\"FAIL\"]),\n",
        "      ('khaula', [99,\"PASS\"]),\n",
        "      ('neethu', [100,\"PASS\"]),\n",
        "      ('sai',[ 37,\"FAIL\"]),\n",
        "  ])\n",
        "\n",
        "  student_marks = (({\n",
        "      'place': student_pairs, 'result': student_result\n",
        "  })\n",
        "            | 'Merge' >> beam.CoGroupByKey()\n",
        "            | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd_aDNEKWGNM",
        "outputId": "a00925d1-d625-4e69-fa65-15f2fdc7b7c6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('vignesh', {'place': ['bangalore'], 'result': [[15, 'FAIL']]})\n",
            "('khaula', {'place': ['hyderabad'], 'result': [[99, 'PASS']]})\n",
            "('neethu', {'place': ['malapur'], 'result': [[100, 'PASS']]})\n",
            "('sai', {'place': ['chennai'], 'result': [[37, 'FAIL']]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  student_pairs = pipeline | \"Student_pairs\">>beam.Create([\n",
        "      ('vignesh', 15),\n",
        "      ('khaula', 99),\n",
        "      ('neethu', 100),\n",
        "      ('sai', 37),\n",
        "  ])\n",
        "\n",
        "  student_result = pipeline  | \"Results\" >> beam.Create([\n",
        "      ('vignesh', \"FAIL\"),\n",
        "      ('khaula',\"PASS\"),\n",
        "      ('neethu',\"PASS\"),\n",
        "      ('sai', \"FAIL\"),\n",
        "  ])\n",
        "\n",
        "  students = (({\n",
        "      'Marks': student_pairs, 'Result': student_result\n",
        "  })\n",
        "  | 'Merge' >> beam.CoGroupByKey()\n",
        "  | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_TXmu7fXQyr",
        "outputId": "38e5f473-2fcf-4635-8187-ff44e14861ad"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('vignesh', {'Marks': [15], 'Result': ['FAIL']})\n",
            "('khaula', {'Marks': [99], 'Result': ['PASS']})\n",
            "('neethu', {'Marks': [100], 'Result': ['PASS']})\n",
            "('sai', {'Marks': [37], 'Result': ['FAIL']})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "GroupIntoBatches:\n",
        "\n",
        "  Batches the input into desired batch size.\n",
        "\n"
      ],
      "metadata": {
        "id": "7B4Zmd7AasRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  batches_with_keys = (\n",
        "      pipeline\n",
        "      | 'Create produce' >> beam.Create([\n",
        "          ('spring', 'üçì'),\n",
        "          ('spring', 'ü•ï'),\n",
        "          ('spring', 'üçÜ'),\n",
        "          ('spring', 'üçÖ'),\n",
        "          ('summer', 'ü•ï'),\n",
        "          ('summer', 'üçÖ'),\n",
        "          ('summer', 'üåΩ'),\n",
        "          ('fall', 'ü•ï'),\n",
        "          ('fall', 'üçÖ'),\n",
        "          ('winter', 'üçÜ'),\n",
        "      ])\n",
        "      | 'Group into batches' >> beam.GroupIntoBatches(4)  #3, #2\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AWs4TE6ZWnC",
        "outputId": "9121e61c-058d-450d-c8f4-4d969c01f505"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('spring', ['üçì', 'ü•ï', 'üçÜ', 'üçÖ'])\n",
            "('summer', ['ü•ï', 'üçÖ', 'üåΩ'])\n",
            "('fall', ['ü•ï', 'üçÖ'])\n",
            "('winter', ['üçÜ'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten and Partition Transform in Apache Beam\n",
        "\n",
        "\n",
        "Partition:\n",
        "‚óè\tPartition is a Beam transform for PCollection objects that store the same data type. It splits a single PCollection into a fixed number of smaller collections.\n",
        "‚óè\tPartition divides the elements of a PCollection according to a partitioning function that you provide.\n",
        "‚óè\tThe partitioning function contains the logic that determines how to split up the elements of the input PCollection into each resulting partition PCollection.\n",
        "‚óè\tThe number of partitions must be determined at graph construction time.\n",
        "‚óè\tPartition accepts a function that receives the number of partitions, and returns the index of the desired partition for the element. The number of partitions passed must be a positive integer, and it must return an integer in the range 0 to num_partitions-1.\n",
        "\n",
        "Flatten:\n",
        "‚óè\tFlatten is a Beam transform for PCollection objects that store the same data type.\n",
        "‚óè\tMerges multiple PCollection objects into a single logical PCollection.\n",
        "\n",
        "Resources:\n",
        "‚óè\thttps://beam.apache.org/documentation/programming-guide/#flatten\n",
        "‚óè\thttps://beam.apache.org/documentation/programming-guide/#partition\n",
        "o\thttps://beam.apache.org/documentation/transforms/python/elementwise/partition/\n"
      ],
      "metadata": {
        "id": "rcrDQSlJukx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Flatten:\n",
        "\n",
        "‚Ä¢ Flatten is a Beam transform for PCollection objects that store the same data type. Flatten merges multiple PCollection objects into a single logical PCollection.\n",
        "\n",
        "‚Ä¢ Kind of Union operation\n"
      ],
      "metadata": {
        "id": "Sunjr_WqsQXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  even_data = (pipeline\n",
        "               |\"Create even data\" >> beam.Create({2,4,6,8,10}))\n",
        "  odd_data = (pipeline\n",
        "              |\"Create odd data\" >> beam.Create({1,3,5,7,9,11}))\n",
        "\n",
        "  result = ((even_data, odd_data) | beam.Flatten()) | beam.Map(print)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx97fx9ravhi",
        "outputId": "cb166305-51a6-4a25-ffb7-170481440ede"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "3\n",
            "5\n",
            "7\n",
            "9\n",
            "11\n",
            "2\n",
            "4\n",
            "6\n",
            "8\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Partition:\n",
        "\n",
        "‚Ä¢ Partition is a Beam transform for PCollection objects that store the same data type. It splits a single PCollection into a fixed number of smaller collections.\n",
        "\n",
        "‚Ä¢ Partition divides the elements of a PCollection according to a partitioning function that you provide.\n",
        "\n",
        "‚Ä¢ The partitioning function contains the logic that determines how to split up the elements of the input PCollection into each resulting partition PCollection.\n",
        "\n",
        "‚Ä¢ The number of partitions must be determined at graph construction time.\n",
        "\n",
        "‚Ä¢ Partition accepts a function that receives the number of partitions, and returns the index of the desired partition for the element. The number of partitions passed must be a positive integer, and it must return an integer in the range 0 to num_partitions-1.\n"
      ],
      "metadata": {
        "id": "Be1vJec7tG79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "p = beam.Pipeline()\n",
        "number = {11,12,13,44,55,61,77,88,99}\n",
        "\n",
        "def partition_fn(element,num_partition):\n",
        "  return 0 if element%2 ==0 else 1\n",
        "\n",
        "\n",
        "number_pc = p| beam.Create(number)| beam.Partition(partition_fn,2)\n",
        "\n",
        "# number_pc[0]| 'Printing even numbers partition' >> beam.Map(print)\n",
        "number_pc[1]| 'Printing odd numbers partition' >> beam.Map(print)\n",
        "\n",
        "p.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abQeUMmGsfhV",
        "outputId": "17677f95-8cce-4928-a3c9-95f608afe57c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n",
            "11\n",
            "13\n",
            "77\n",
            "55\n",
            "61\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7cc46dae0160>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Latest, Max, Min Sample, Sum and Top Transform in Apache Beam\n",
        "\n",
        "\n",
        "Latest:\n",
        "‚óè\tGets the element with the latest timestamp.\n",
        "Max:\n",
        "‚óè\tGets the element with the maximum value within each aggregation.\n",
        "Min:\n",
        "‚óè\tGets the element with the minimum value within each aggregation.\n",
        "Mean:\n",
        "‚óè\tTransforms for computing the arithmetic mean of the elements in a collection, or the mean of the values associated with each key in a collection of key-value pairs.\n",
        "Sample:\n",
        "‚óè\tTransforms for taking samples of the elements in a collection, or samples of the values associated with each key in a collection of key-value pairs.\n",
        "Sum:\n",
        "‚óè\tSums all the elements within each aggregation.\n",
        "Top:\n",
        "‚óè\tTransforms for finding the largest (or smallest) set of elements in a collection, or the largest (or smallest) set of values associated with each key in a collection of key-value pairs.\n",
        "Resources:\n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/aggregation/latest/\n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/aggregation/max/\n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/aggregation/min/\n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/aggregation/mean/\n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/aggregation/sample/\n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/aggregation/sum/\n",
        "‚óè\thttps://beam.apache.org/documentation/transforms/python/aggregation/top/\n"
      ],
      "metadata": {
        "id": "hiqxBbd_uCMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "EmGRIwaftbjY"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Latest:\n",
        "\n",
        "  Gets the element with the latest timestamp.\n",
        "  we create a pipeline with a PCollection of produce with a timestamp for their harvest date. We use Latest to get the element with the latest timestamp from the PCollection.\n",
        "\n"
      ],
      "metadata": {
        "id": "h8Zvt9JFvKGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def to_unix_time(time_str, format='%Y-%m-%d %H:%M:%S'):\n",
        "  return time.mktime(time.strptime(time_str, format))\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  latest_element = (\n",
        "      pipeline\n",
        "      | 'Create crops' >> beam.Create([\n",
        "          {\n",
        "              'item': 'ü•¨', 'harvest': '2020-02-24 00:00:00'\n",
        "          },\n",
        "          {\n",
        "              'item': 'üçì', 'harvest': '2020-06-16 00:00:00'\n",
        "          },\n",
        "          {\n",
        "              'item': 'ü•ï', 'harvest': '2020-07-17 00:00:00'\n",
        "          },\n",
        "          {\n",
        "              'item': 'üçÜ', 'harvest': '2020-10-26 00:00:00'\n",
        "          },\n",
        "          {\n",
        "              'item': 'üçÖ', 'harvest': '2020-10-01 00:00:00'\n",
        "          },\n",
        "      ])\n",
        "      | 'With timestamps' >> beam.Map(\n",
        "          lambda crop: beam.window.TimestampedValue(\n",
        "              crop['item'], to_unix_time(crop['harvest'])))\n",
        "      | 'Get latest element' >> beam.combiners.Latest.Globally()\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icgAyxTivGwO",
        "outputId": "8a59c895-996d-4d57-a263-d24763d9516c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üçÜ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_unix_time(time_str, format='%Y-%m-%d %H:%M:%S'):\n",
        "  return time.mktime(time.strptime(time_str, format))\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  latest_elements_per_key = (\n",
        "      pipeline\n",
        "      | 'Create crops' >> beam.Create([\n",
        "          ('spring', {\n",
        "              'item': 'ü•ï', 'harvest': '2020-06-28 00:00:00'\n",
        "          }),\n",
        "          ('spring', {\n",
        "              'item': 'üçì', 'harvest': '2020-06-16 00:00:00'\n",
        "          }),\n",
        "          ('summer', {\n",
        "              'item': 'ü•ï', 'harvest': '2020-07-17 00:00:00'\n",
        "          }),\n",
        "          ('summer', {\n",
        "              'item': 'üçì', 'harvest': '2020-08-26 00:00:00'\n",
        "          }),\n",
        "          ('summer', {\n",
        "              'item': 'üçÜ', 'harvest': '2020-09-04 00:00:00'\n",
        "          }),\n",
        "          ('summer', {\n",
        "              'item': 'ü•¨', 'harvest': '2020-09-18 00:00:00'\n",
        "          }),\n",
        "          ('summer', {\n",
        "              'item': 'üçÖ', 'harvest': '2020-09-22 00:00:00'\n",
        "          }),\n",
        "          ('autumn', {\n",
        "              'item': 'üçÖ', 'harvest': '2020-10-01 00:00:00'\n",
        "          }),\n",
        "          ('autumn', {\n",
        "              'item': 'ü•¨', 'harvest': '2020-10-20 00:00:00'\n",
        "          }),\n",
        "          ('autumn', {\n",
        "              'item': 'üçÜ', 'harvest': '2020-10-26 00:00:00'\n",
        "          }),\n",
        "          ('winter', {\n",
        "              'item': 'ü•¨', 'harvest': '2020-02-24 00:00:00'\n",
        "          }),\n",
        "      ])\n",
        "      | 'With timestamps' >> beam.Map(\n",
        "          lambda pair: beam.window.TimestampedValue(\n",
        "              (pair[0], pair[1]['item']), to_unix_time(pair[1]['harvest'])))\n",
        "      | 'Get latest elements per key' >> beam.combiners.Latest.PerKey()\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7CIRzKMv5uN",
        "outputId": "1fb0af9f-b19f-4816-9ff6-5aab78a1f848"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('spring', 'ü•ï')\n",
            "('summer', 'üçÖ')\n",
            "('autumn', 'üçÜ')\n",
            "('winter', 'ü•¨')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Max:\n",
        "\n",
        "  Gets the element with the maximum value within each aggregation.\n",
        "  we create a pipeline with a PCollection. Then, we get the element with the maximum value in different ways.\n",
        "\n"
      ],
      "metadata": {
        "id": "iUFhtE5Dwq_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  max_element = (\n",
        "      pipeline\n",
        "      | 'Create numbers' >> beam.Create([3, 4, 1, 2])\n",
        "      # | 'Get max value' >> beam.CombineGlobally(lambda elements: max(elements or [None]))\n",
        "      | 'Get max value' >> beam.CombineGlobally(max)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuXnVfk4whyE",
        "outputId": "82cb1a9c-46b0-4536-b596-9b04c1f72916"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#when PCollection is key-value pair\n",
        "with beam.Pipeline() as pipeline:\n",
        "  elements_with_max_value_per_key = (\n",
        "      pipeline\n",
        "      | 'Create produce' >> beam.Create([\n",
        "          ('ü•ï', 3),\n",
        "          ('ü•ï', 2),\n",
        "          ('üçÜ', 1),\n",
        "          ('üçÖ', 4),\n",
        "          ('üçÖ', 5),\n",
        "          ('üçÖ', 3),\n",
        "      ])\n",
        "      | 'Get max value per key' >> beam.CombinePerKey(max)\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzh4xETDx2YM",
        "outputId": "f3a0c742-0e28-4083-951c-1ff2e1125729"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ü•ï', 3)\n",
            "('üçÜ', 1)\n",
            "('üçÖ', 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Min:\n",
        "\n",
        "  Gets the element with the minimum value within each aggregation.\n",
        "  we create a pipeline with a PCollection. Then, we get the element with the minimum value in different ways.\n",
        "\n"
      ],
      "metadata": {
        "id": "ffNLfedzxfi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  min_element = (\n",
        "      pipeline\n",
        "      | 'Create numbers' >> beam.Create([3, 4, 1, 2])\n",
        "      | 'Get min value' >>\n",
        "      beam.CombineGlobally(lambda elements: min(elements or [-1]))\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea5Gm9DGw2PL",
        "outputId": "cca64604-a7d3-4113-d2de-0f3f9d9bdb5b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  elements_with_min_value_per_key = (\n",
        "      pipeline\n",
        "      | 'Create produce' >> beam.Create([\n",
        "          ('ü•ï', 3),\n",
        "          ('ü•ï', 2),\n",
        "          ('üçÜ', 1),\n",
        "          ('üçÖ', 4),\n",
        "          ('üçÖ', 5),\n",
        "          ('üçÖ', 3),\n",
        "      ])\n",
        "      | 'Get min value per key' >> beam.CombinePerKey(min)\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ouiHU3WxjBM",
        "outputId": "9bc4fcc1-bb19-4f5c-d953-356f3a84cb59"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ü•ï', 2)\n",
            "('üçÜ', 1)\n",
            "('üçÖ', 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Mean:\n",
        "\n",
        "  Transforms for computing the arithmetic mean of the elements in a collection, or the mean of the values associated with each key in a collection of key-value pairs.\n",
        "  we create a pipeline with a PCollection. Then, we get the element with the average value in different ways.\n",
        "\n"
      ],
      "metadata": {
        "id": "J9xOJUXayJ2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Global mean value\n",
        "with beam.Pipeline() as pipeline:\n",
        "  mean_element = (\n",
        "      pipeline\n",
        "      | 'Create numbers' >> beam.Create([3, 4, 1, 2])\n",
        "      | 'Get mean value' >> beam.combiners.Mean.Globally()\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xPPxoYPxtoK",
        "outputId": "a8157e3c-431f-4e41-f355-bf404d799b1a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mean value based on key-value pair\n",
        "with beam.Pipeline() as pipeline:\n",
        "  elements_with_mean_value_per_key = (\n",
        "      pipeline\n",
        "      | 'Create produce' >> beam.Create([\n",
        "          ('ü•ï', 3),\n",
        "          ('ü•ï', 2),\n",
        "          ('üçÜ', 1),\n",
        "          ('üçÖ', 4),\n",
        "          ('üçÖ', 5),\n",
        "          ('üçÖ', 3),\n",
        "      ])\n",
        "      | 'Get mean value per key' >> beam.combiners.Mean.PerKey()\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ib5iGH-yTN1",
        "outputId": "735e209f-8213-451c-be9a-566c8361ff01"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ü•ï', 2.5)\n",
            "('üçÜ', 1.0)\n",
            "('üçÖ', 4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Sample:\n",
        "\n",
        "  Transforms for taking samples of the elements in a collection, or samples of the values associated with each key in a collection of key-value pairs.\n",
        "  we create a pipeline with a PCollection. Then, we get a random sample of elements in different ways.\n",
        "\n",
        "Sample.FixedSizeGlobally() to get a fixed-size random sample of elements from the entire PCollection.\n"
      ],
      "metadata": {
        "id": "dbx9sAoC1OBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  sample = (\n",
        "      pipeline\n",
        "      | 'Create produce' >> beam.Create([\n",
        "          'üçì Strawberry',\n",
        "          'ü•ï Carrot',\n",
        "          'üçÜ Eggplant',\n",
        "          'üçÖ Tomato',\n",
        "          'ü•î Potato',\n",
        "      ])\n",
        "      | 'Sample N elements' >> beam.combiners.Sample.FixedSizeGlobally(2)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv0_fdIByaib",
        "outputId": "f2bd7026-73e8-4af1-8adf-432ca34c5c38"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['üçì Strawberry', 'üçÜ Eggplant']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  samples_per_key = (\n",
        "      pipeline\n",
        "      | 'Create produce' >> beam.Create([\n",
        "          ('spring', 'üçì'),\n",
        "          ('spring', 'ü•ï'),\n",
        "          ('spring', 'üçÜ'),\n",
        "          ('spring', 'üçÖ'),\n",
        "          ('summer', 'ü•ï'),\n",
        "          ('summer', 'üçÖ'),\n",
        "          ('summer', 'üåΩ'),\n",
        "          ('fall', 'ü•ï'),\n",
        "          ('fall', 'üçÖ'),\n",
        "          ('winter', 'üçÜ'),\n",
        "      ])\n",
        "      | 'Samples per key' >> beam.combiners.Sample.FixedSizePerKey(3)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_ri39r81Wdm",
        "outputId": "142d7838-7f95-485f-f48c-49ae7b1983e3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('spring', ['üçÜ', 'üçÖ', 'üçì'])\n",
            "('summer', ['üåΩ', 'ü•ï', 'üçÖ'])\n",
            "('fall', ['üçÖ', 'ü•ï'])\n",
            "('winter', ['üçÜ'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Sum:\n",
        "\n",
        "  Sums all the elements within each aggregation.\n",
        "  we create a pipeline with a PCollection. Then, we get the sum of all the element values in different ways.\n",
        "\n",
        "Combine.PerKey() to get the sum of all the element values for each unique key in a PCollection of key-values.\n"
      ],
      "metadata": {
        "id": "orHIXBwz2A7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  total = (\n",
        "      pipeline\n",
        "      | 'Create numbers' >> beam.Create([3, 4, 1, 2])\n",
        "      | 'Sum values' >> beam.CombineGlobally(sum)\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clrgGTmm1r18",
        "outputId": "ea4463b0-9517-4c5c-a90d-7aa04fdb7e3d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  totals_per_key = (\n",
        "      pipeline\n",
        "      | 'Create produce' >> beam.Create([\n",
        "          ('ü•ï', 3),\n",
        "          ('ü•ï', 2),\n",
        "          ('üçÜ', 1),\n",
        "          ('üçÖ', 4),\n",
        "          ('üçÖ', 5),\n",
        "          ('üçÖ', 3),\n",
        "      ])\n",
        "      | 'Sum values per key' >> beam.CombinePerKey(sum)\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3ZrBsCB2Im1",
        "outputId": "b1c0c466-cf72-4025-8d06-4cebfabf37d2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ü•ï', 5)\n",
            "('üçÜ', 1)\n",
            "('üçÖ', 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Top:\n",
        "\n",
        "  Transforms for finding the largest (or smallest) set of elements in a collection, or the largest (or smallest) set of values associated with each key in a collection of key-value pairs.\n",
        "  \n",
        "  we create a pipeline with a PCollection. Then, we get the largest or smallest elements in different ways.\n",
        "\n"
      ],
      "metadata": {
        "id": "xucW8-1V2bm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  largest_elements = (\n",
        "      pipeline\n",
        "      | 'Create numbers' >> beam.Create([3, 4, 1, 2])\n",
        "      | 'Largest N values' >> beam.combiners.Top.Largest(2)\n",
        "      | beam.Map(print))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Asc_XX_2K5T",
        "outputId": "8e2c00f4-b09c-4d11-e291-58618e78d4fa"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  largest_elements = (\n",
        "      pipeline\n",
        "      | 'Create numbers' >> beam.Create([3, 4, 1, 2])\n",
        "      | 'Largest N values' >> beam.combiners.Top.Smallest(2)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJmj191U3A-4",
        "outputId": "11d47047-7b37-4a11-bc5c-be8c724942a4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  largest_elements_per_key = (\n",
        "      pipeline\n",
        "      | 'Create produce' >> beam.Create([\n",
        "          ('ü•ï', 3),\n",
        "          ('ü•ï', 2),\n",
        "          ('üçÜ', 1),\n",
        "          ('üçÖ', 4),\n",
        "          ('üçÖ', 5),\n",
        "          ('üçÖ', 3),\n",
        "      ])\n",
        "      | 'Largest N values per key' >> beam.combiners.Top.LargestPerKey(2)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvnFDXkI2fJc",
        "outputId": "80c3b22d-3009-45b4-a3e6-c0c3a8476e5a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ü•ï', [3, 2])\n",
            "('üçÜ', [1])\n",
            "('üçÖ', [5, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  largest_elements_per_key = (\n",
        "      pipeline\n",
        "      | 'Create produce' >> beam.Create([\n",
        "          ('ü•ï', 3),\n",
        "          ('ü•ï', 2),\n",
        "          ('üçÜ', 1),\n",
        "          ('üçÖ', 4),\n",
        "          ('üçÖ', 5),\n",
        "          ('üçÖ', 3),\n",
        "      ])\n",
        "      | 'Largest N values per key' >> beam.combiners.Top.SmallestPerKey(2)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFXkS5St2vh1",
        "outputId": "f0fb7a05-1fb6-46d6-da6c-69f33c4765f8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ü•ï', [2, 3])\n",
            "('üçÜ', [1])\n",
            "('üçÖ', [3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Side Inputs:\n",
        "\n",
        "‚Ä¢\tA side input is an additional input that your DoFn can access each time it processes an element in the input PCollection.\n",
        "\n",
        "‚Ä¢\tIn addition to the main input PCollection, you can provide additional inputs to a ParDo transform in the form of side inputs.\n",
        "\n",
        "‚Ä¢\tSide inputs are useful if your ParDo needs to inject additional data when processing each element in the input PCollection, but the additional data needs to be determined at runtime (and not hard-coded).\n",
        "\n",
        "‚Ä¢\tSide inputs must be small in size and not as big as pcollection because it has to be kept in memory of each worker\n",
        "\n",
        "‚Ä¢\tSuch values might be determined by the input data, or depend on a different branch of your pipeline.\n",
        "\n",
        "Additional outputs:  \n",
        "\n",
        "‚Ä¢\tWhile ParDo always produces a main output PCollection (as the return value from apply), you can also have your ParDo produce any number of additional output PCollections.\n",
        "\n",
        "‚Ä¢\tIf you choose to have multiple outputs, your ParDo returns all of the output PCollections (including the main output) bundled together.\n",
        "\n",
        "Resources:  \n",
        "‚Ä¢\thttps://beam.apache.org/documentation/patterns/side-inputs/\n",
        "\n",
        "‚Ä¢\thttps://beam.apache.org/documentation/programming-guide/#additional-outputs\n",
        "\n",
        "‚Ä¢\thttps://beam.apache.org/documentation/programming-guide/#side-inputs  \n"
      ],
      "metadata": {
        "id": "OJBfdmeWdlXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Side Inputs:\n",
        "\n",
        "‚Ä¢ A side input is an additional input that your DoFn can access each time it processes an element in the input PCollection.\n",
        "\n",
        "‚Ä¢ In addition to the main input PCollection, you can provide additional inputs to a ParDo transform in the form of side inputs.\n"
      ],
      "metadata": {
        "id": "JCj8rUgkew4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = beam.Pipeline()\n",
        "\n",
        "input_list = list()\n",
        "with open ('students_exclude.txt','r') as exclude_file:\n",
        "  for stud_id in exclude_file:\n",
        "    input_list.append(stud_id.rstrip())\n",
        "\n",
        "print(input_list)"
      ],
      "metadata": {
        "id": "yJqUFkTA3Ipk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94806163-75df-4a4c-ef9a-433feceabe52"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '3', '7', '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitRow(beam.DoFn):\n",
        "  def process(self,element,input_list):\n",
        "    customer = element.split(',')\n",
        "    if customer[0] not in input_list:\n",
        "      return [customer]\n",
        "\n",
        "customers = (\n",
        "    p1\n",
        "    |beam.io.ReadFromText('Students_age.txt')\n",
        "    |beam.ParDo(SplitRow(),input_list)  #can pass any number of side inputs in this ParDo function\n",
        "    # |beam.Map(print)\n",
        "    |beam.io.WriteToText('data/output')\n",
        "\n",
        ")\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLGmcf3eez0Y",
        "outputId": "c35f7d2e-7488-4b9b-c876-5baf73fdcee0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2', 'farooqui', 'hyd', '26']\n",
            "['4', 'neethu', 'mla', '27', '']\n",
            "['5', 'joey', 'ny', '57']\n",
            "['6', 'ross', 'la', '60']\n",
            "['8', 'lois', 'us', '50']\n",
            "['10', 'sai', 'chn', '29']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:No shards found to finalize. num_shards: 1, skipped: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/output-00000-of-00001\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7cc465a31390>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat \"/content/data/output-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlsP151MfSOI",
        "outputId": "3465e72b-99ce-4fbb-b54d-74699085d348"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2', 'farooqui', 'hyd', '26']\n",
            "['4', 'neethu', 'mla', '27', '']\n",
            "['5', 'joey', 'ny', '57']\n",
            "['6', 'ross', 'la', '60']\n",
            "['8', 'lois', 'us', '50']\n",
            "['10', 'sai', 'chn', '29']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 data/output-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ea-MkU4fiZI",
        "outputId": "9c3fd9ab-4e3e-4e99-b256-d092964af2ed"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2', 'farooqui', 'hyd', '26']\n",
            "['4', 'neethu', 'mla', '27', '']\n",
            "['5', 'joey', 'ny', '57']\n",
            "['6', 'ross', 'la', '60']\n",
            "['8', 'lois', 'us', '50']\n",
            "['10', 'sai', 'chn', '29']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = beam.Pipeline()\n",
        "\n",
        "side_list = list()\n",
        "with open ('students_exclude.txt','r') as exclude_file:\n",
        "  for cust_id in exclude_file:\n",
        "    side_list.append(cust_id.rstrip())\n",
        "\n",
        "print(side_list)\n",
        "\n",
        "class SplitRow(beam.DoFn):\n",
        "  def process(self,element,side_list):\n",
        "    customer = element.split(',')\n",
        "    if customer[0] not in side_list:\n",
        "      return [customer]\n",
        "\n",
        "class ProcessCustomers(beam.DoFn):\n",
        "  def process(self,element,country,start_char):\n",
        "    if(element[2]==country):\n",
        "      yield  element\n",
        "    else:\n",
        "      yield  beam.pvalue.TaggedOutput('Other_student',element)\n",
        "    if(element[1].startswith('r')):\n",
        "       yield  beam.pvalue.TaggedOutput('Names_r',element)\n",
        "\n",
        "\n",
        "\n",
        "customers = (\n",
        "    p1\n",
        "    |beam.io.ReadFromText('Students_age.txt')\n",
        "    |beam.ParDo(SplitRow(),side_list)\n",
        "    |beam.ParDo(ProcessCustomers(),'chn','r').with_outputs('Names_r','Other_student',main='Chennai_Cust')\n",
        ")\n",
        "\n",
        "chennai_customers = customers.Chennai_Cust\n",
        "other_cities_customers = customers.Other_student\n",
        "customer_withname_r = customers.Names_r\n",
        "\n",
        "chennai_customers | 'Write Chennai Students PCollection' >> beam.io.WriteToText(\"chennai\")\n",
        "other_cities_customers  | 'Write Students PCollection that lives in other cities' >> beam.io.WriteToText(\"students_other_cities\")\n",
        "customer_withname_r  | 'Write Students names with r PCollection' >> beam.io.WriteToText(\"customers_names_r\")\n",
        "\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTOBA1fhfyn6",
        "outputId": "ac09df83-8ddc-47ae-fa9d-7d50f4daf699"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '3', '7', '9']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7cc465a191e0>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cat chennai-00000-of-00001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe3mU2VkgwbH",
        "outputId": "34629842-f127-4efd-c7f1-cd680faa56a2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['10', 'sai', 'chn', '29']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!cat students_other_cities-00000-of-00001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbPB8E5Ch9XQ",
        "outputId": "4ed89876-a541-4ee4-cbc2-056c59c15178"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2', 'farooqui', 'hyd', '26']\n",
            "['4', 'neethu', 'mla', '27', '']\n",
            "['5', 'joey', 'ny', '57']\n",
            "['6', 'ross', 'la', '60']\n",
            "['8', 'lois', 'us', '50']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat customers_names_r-00000-of-00001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbF7VVJMh_ir",
        "outputId": "d3526168-30c8-42a5-8fbb-e11962aabf72"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['6', 'ross', 'la', '60']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Composite Transformation in Apache Beam:\n",
        "\n",
        "Composite Transform:\n",
        "\n",
        "‚Ä¢\tTransforms can have a nested structure, where a complex transform performs multiple simpler transforms (such as more than one ParDo, Combine, GroupByKey, or even other composite transforms). These transforms are called composite transforms.\n",
        "\n",
        "‚Ä¢\tNesting multiple transforms inside a single composite transform can make your code more modular and easier to understand.\n",
        "Creating a composite transform:\n",
        "\n",
        "‚Ä¢\tTo create your own composite transform, create a subclass of the PTransform class and override the expand method to specify the actual processing logic.\n",
        "\n",
        "‚Ä¢\tThe transforms can include core transforms, composite transforms, or the transforms included in the Beam SDK libraries.\n",
        "\n",
        "‚Ä¢\tThe following code sample shows how to declare a PTransform that accepts a PCollection of Strings for input, and outputs a PCollection of Integers:\n",
        "\n",
        "‚Ä¢\tThe expand method is where you add the processing logic for the PTransform. Your override of expand must accept the appropriate type of input PCollection as a parameter, and specify the output PCollection as the return value.\n",
        "\n",
        "‚Ä¢\tYou can include as many transforms as you want. These transforms can include core transforms, composite transforms, or the transforms included in the Beam SDK libraries.\n",
        "\n",
        "‚Ä¢\tYour composite transform‚Äôs parameters and return value must match the initial input type and final return type for the entire transform, even if the transform‚Äôs intermediate data changes type multiple times.\n",
        "\n",
        "Resources:\n",
        "\n",
        "‚Ä¢\thttps://beam.apache.org/documentation/programming-guide/#composite-transforms\n",
        "\n",
        "‚Ä¢\thttps://beam.apache.org/releases/pydoc/2.36.0/apache_beam.transforms.html\n"
      ],
      "metadata": {
        "id": "qUDOtR9live9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "def SplitRow(element):\n",
        "  return element.split(',')\n",
        "\n",
        "\n",
        "def filter_on_count(element):\n",
        "  name, count = element\n",
        "  if count > 30:\n",
        "    return element\n",
        "\n",
        "def format_output(element):\n",
        "  name, count = element\n",
        "  return (name.encode('ascii'),str(count),'Experienced employee')"
      ],
      "metadata": {
        "id": "Jk522kZ4iBK-"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Using normal transformation like\n",
        "\n",
        "    Map\n",
        "    Filter\n",
        "    CombinePerKey\n",
        "\n",
        "For three different operations and it includes more code, memory space and time as well.\n"
      ],
      "metadata": {
        "id": "eVVGdNzGje5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as p:\n",
        "  input_data = (p\n",
        "                      | \"Read from text file\" >> beam.io.ReadFromText('dept_data.txt')\n",
        "                      | \"Split rows\" >> beam.Map(SplitRow)\n",
        "                   )\n",
        "\n",
        "  accounts_count = (\n",
        "                      input_data\n",
        "                      | 'Get all Accounts dept persons' >> beam.Filter(lambda record: record[3] == 'Accounts')\n",
        "                      | 'Pair each accounts employee with 1 accounts' >> beam.Map(lambda record: (\"Accounts, \" +record[1], 1))\n",
        "                      | 'Group and sum1 accounts' >> beam.CombinePerKey(sum)\n",
        "                      | 'count filter accounts' >> beam.Filter(filter_on_count)\n",
        "                      | 'Regular accounts employee' >> beam.Map(format_output)\n",
        "                      | 'Write results for account' >> beam.io.WriteToText('data/Account_quick')\n",
        "                 )\n",
        "\n",
        "  hr_count = (\n",
        "                      input_data\n",
        "                      | 'Get all HR  dept persons' >> beam.Filter(lambda record: record[3] == 'HR')\n",
        "                      | 'Pair each HR employee with 1 hr' >> beam.Map(lambda record: (\"HR, \" +record[1], 1))\n",
        "                      | 'Group and sum1 hr' >> beam.CombinePerKey(sum)\n",
        "                      | 'count filter hr' >> beam.Filter(filter_on_count)\n",
        "                      | 'Regular accounts employee hr' >> beam.Map(format_output)\n",
        "                      | 'Write results for HR ' >> beam.io.WriteToText('data/HR_quick')\n",
        "                 )\n",
        "\n",
        "  finance_count = (\n",
        "                  input_data\n",
        "                  | 'Get all finance dept persons' >> beam.Filter(lambda record: record[3] == 'Finance')\n",
        "                  | 'Pair each finance employee with 1 finance' >> beam.Map(lambda record: (\"Finance, \" +record[1], 1))\n",
        "                  | 'Group and sum1 finance' >> beam.CombinePerKey(sum)\n",
        "                  | 'count filter finance' >> beam.Filter(filter_on_count)\n",
        "                  | 'Regular accounts employee1 finance' >> beam.Map(format_output)\n",
        "                  | 'Write results for finance' >> beam.io.WriteToText('data/Finance_quick')\n",
        "                   )"
      ],
      "metadata": {
        "id": "8fUKMzTXjcI_"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!{('head -n 10 data/Account_quick-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkyeE6KGjjPn",
        "outputId": "bd48f902-18a5-44ce-db66-9ab09a8b90c8"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(b'Accounts, Marco', '31', 'Experienced employee')\n",
            "(b'Accounts, Rebekah', '31', 'Experienced employee')\n",
            "(b'Accounts, Itoe', '31', 'Experienced employee')\n",
            "(b'Accounts, Edouard', '31', 'Experienced employee')\n",
            "(b'Accounts, Kyle', '62', 'Experienced employee')\n",
            "(b'Accounts, Kumiko', '31', 'Experienced employee')\n",
            "(b'Accounts, Gaston', '31', 'Experienced employee')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 data/Finance_quick-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvuTAOoukcMx",
        "outputId": "6995613a-22ab-460e-e1d1-24235eb1e5c8"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(b'Finance, Kumiko', '31', 'Experienced employee')\n",
            "(b'Finance, Wendy', '31', 'Experienced employee')\n",
            "(b'Finance, Cristobal', '31', 'Experienced employee')\n",
            "(b'Finance, Erika', '31', 'Experienced employee')\n",
            "(b'Finance, Sebastien', '31', 'Experienced employee')\n",
            "(b'Finance, Valerie', '31', 'Experienced employee')\n",
            "(b'Finance, Dolly', '31', 'Experienced employee')\n",
            "(b'Finance, Emily', '31', 'Experienced employee')\n",
            "(b'Finance, Kaori', '31', 'Experienced employee')\n",
            "(b'Finance, Hitomi', '31', 'Experienced employee')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Composite Transforms:\n",
        "\n",
        "  Transforms can have a nested structure, where a complex transform performs multiple simpler transforms (such as more than one ParDo, Combine, GroupByKey, or even other composite transforms). These transforms are called composite transforms.\n",
        "\n"
      ],
      "metadata": {
        "id": "Nt2qmbhnkgiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class MyTransform(beam.PTransform):\n",
        "\n",
        "  def expand(self, input_coll):\n",
        "\n",
        "    a = (\n",
        "        input_coll\n",
        "                       | 'Group and sum1' >> beam.CombinePerKey(sum)\n",
        "                       | 'count filter accounts' >> beam.Filter(filter_on_count)\n",
        "                       | 'Regular accounts employee' >> beam.Map(format_output)\n",
        "\n",
        "    )\n",
        "    return a\n",
        "\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "  input_data = (p\n",
        "                      | \"Read from text file\" >> beam.io.ReadFromText('dept_data.txt')\n",
        "                      | \"Split rows\" >> beam.Map(SplitRow)\n",
        "                   )\n",
        "\n",
        "  accounts_count = (\n",
        "                      input_data\n",
        "                      | 'Get all Accounts dept persons' >> beam.Filter(lambda record: record[3] == 'Accounts')\n",
        "                      | 'Pair each accounts employee with 1' >> beam.Map(lambda record: (\"Accounts, \" +record[1], 1))\n",
        "                      | 'composite accounts' >> MyTransform()\n",
        "                      | 'Write results for account' >> beam.io.WriteToText('data/Account')\n",
        "                 )\n",
        "\n",
        "  finance_count = (\n",
        "                  input_data\n",
        "                  | 'Get all Finance dept persons' >> beam.Filter(lambda record: record[3] == 'Finance')\n",
        "                  | 'Pair each Finance employee with 1' >> beam.Map(lambda record: (\"Finance, \" +record[1], 1))\n",
        "                  | 'composite Finance' >> MyTransform()\n",
        "                  | 'Write results for Finance' >> beam.io.WriteToText('data/Finance')\n",
        "            )\n",
        "\n"
      ],
      "metadata": {
        "id": "k1cCJV78kejo"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 data/Account-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO4Kd7vPkqy4",
        "outputId": "60d9109c-6956-4dc2-8951-6be9a999b978"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(b'Accounts, Marco', '31', 'Experienced employee')\n",
            "(b'Accounts, Rebekah', '31', 'Experienced employee')\n",
            "(b'Accounts, Itoe', '31', 'Experienced employee')\n",
            "(b'Accounts, Edouard', '31', 'Experienced employee')\n",
            "(b'Accounts, Kyle', '62', 'Experienced employee')\n",
            "(b'Accounts, Kumiko', '31', 'Experienced employee')\n",
            "(b'Accounts, Gaston', '31', 'Experienced employee')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 data/Finance-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JVY1Yn-kt3o",
        "outputId": "3f407695-39b8-4ad6-b502-f3c930a07fad"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(b'Finance, Kumiko', '31', 'Experienced employee')\n",
            "(b'Finance, Wendy', '31', 'Experienced employee')\n",
            "(b'Finance, Cristobal', '31', 'Experienced employee')\n",
            "(b'Finance, Erika', '31', 'Experienced employee')\n",
            "(b'Finance, Sebastien', '31', 'Experienced employee')\n",
            "(b'Finance, Valerie', '31', 'Experienced employee')\n",
            "(b'Finance, Dolly', '31', 'Experienced employee')\n",
            "(b'Finance, Emily', '31', 'Experienced employee')\n",
            "(b'Finance, Kaori', '31', 'Experienced employee')\n",
            "(b'Finance, Hitomi', '31', 'Experienced employee')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine Core Transform in Apache Beam:\n",
        "\n",
        "Combine:\n",
        "\n",
        "‚óè\tCombine is a Beam transform for combining collections of elements or values in your data.\n",
        "\n",
        "‚óè\tCombine has variants that work on entire PCollections, and some that combine the values for each key in PCollections of key/value pairs.\n",
        "\n",
        "‚óè\tWhen you apply a Combine transform, you must provide the function that contains the logic for combining the elements or values.\n",
        "\n",
        "‚óè\tThe combining function should be commutative and associative.\n",
        "\n",
        "‚óè\tThe Beam SDK also provides some pre-built combine functions for common numeric combination operations such as sum, min, and max.\n",
        "\n",
        "‚óè\tcomplex combination operations might require you to create a subclass of CombineFn that has an accumulation type distinct from the input/output type.\n",
        "Advanced combinations using CombineFn:\n",
        "\n",
        "o\tA general combining operation consists of four operations. When you create a subclass of CombineFn, you must provide four operations by overriding the corresponding methods:\n",
        "\n",
        "o\tCreate Accumulator - creates a new ‚Äúlocal‚Äù accumulator\n",
        "\n",
        "o\tAdd Input - adds an input element to an accumulator, returning the accumulator value.\n",
        "\n",
        "o\tMerge Accumulators - merges several accumulators into a single accumulator; this is how data in multiple accumulators is combined before the final calculation.\n",
        "\n",
        "o\tExtract Output - performs the final computation.\n",
        "Three types of Aggregator function is supported by beam. They are.\n",
        "\n",
        "CombineGlobally:  Combines all elements in a collection.\n",
        "\n",
        "CombinePerKey: Combines all elements for each key in a collection.\n",
        "\n",
        "CombineValues:  Combines an iterable of values in a keyed collection of elements.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Resources:\n",
        "\n",
        "‚óè\thttps://beam.apache.org/documentation/programming-guide/#combine\n",
        "\n",
        "o\thttps://beam.apache.org/documentation/transforms/python/aggregation/combineglobally/\n",
        "\n",
        "o\thttps://beam.apache.org/documentation/transforms/python/aggregation/combineperkey/\n",
        "\n",
        "o\thttps://beam.apache.org/documentation/transforms/python/aggregation/combinevalues/\n"
      ],
      "metadata": {
        "id": "VZ5ur93OlKV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "CombineGlobally:\n",
        "\n",
        "  Combines all elements in a collection.\n",
        "\n",
        "The more general way to combine elements, and the most flexible, is with a class that inherits from CombineFn.\n",
        "\n",
        "  CombineFn.create_accumulator(): This creates an empty accumulator. For example, an empty accumulator for a sum would be 0, while an empty accumulator for a product (multiplication) would be 1.\n",
        "\n",
        "  CombineFn.add_input(): Called once per element. Takes an accumulator and an input element, combines them and returns the updated accumulator.\n",
        "\n",
        "  CombineFn.merge_accumulators(): Multiple accumulators could be processed in parallel, so this function helps merging them into a single accumulator.\n",
        "\n",
        "  CombineFn.extract_output(): It allows to do additional calculations before extracting a result.\n",
        "\n"
      ],
      "metadata": {
        "id": "FRYsnAhPnSyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class AverageFn(beam.CombineFn):\n",
        "  def create_accumulator(self):\n",
        "    return (0.0, 0)\n",
        "\n",
        "  def add_input(self, sum_count, input):\n",
        "    (sum, count) = sum_count\n",
        "    return sum + input, count + 1\n",
        "\n",
        "  def merge_accumulators(self, accumulators):\n",
        "    sums, counts = zip(*accumulators)\n",
        "    return sum(sums), sum(counts)\n",
        "\n",
        "  def extract_output(self, sum_count):\n",
        "    (sum, count) = sum_count\n",
        "    return sum / count if count else float('NaN')\n",
        "\n",
        "\n",
        "with beam.Pipeline() as p:\n",
        "  input_data = (p\n",
        "                | \"Create data\" >> beam.Create([21,45,78,99,1,22,5])\n",
        "                | \"Combine Globally\" >> beam.CombineGlobally(AverageFn())\n",
        "                |\"Write to Local\">> beam.io.WriteToText('data/result'))\n",
        "\n"
      ],
      "metadata": {
        "id": "bvvnjBLlkv-Y"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{'head -n 10 data/result-00000-of-00001'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0l50UPjpypK",
        "outputId": "196badc1-2260-44f1-db98-d2b3ac26475e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38.714285714285715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "CombinePerKey:\n",
        "\n",
        "    Combines all elements for each key in a collection.\n",
        "\n"
      ],
      "metadata": {
        "id": "gQxyREOxpzwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  total = (\n",
        "      pipeline\n",
        "      | 'Create plant counts' >> beam.Create([\n",
        "          ('ü•ï', 3),\n",
        "          ('ü•ï', 2),\n",
        "          ('üçÜ', 1),\n",
        "          ('üçÖ', 4),\n",
        "          ('üçÖ', 5),\n",
        "          ('üçÖ', 3),\n",
        "      ])\n",
        "      | 'Sum' >> beam.CombinePerKey(sum)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8vi2pSCp67X",
        "outputId": "b5995c4a-17e5-4869-a0c1-5d09b063cbfc"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ü•ï', 5)\n",
            "('üçÜ', 1)\n",
            "('üçÖ', 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def saturated_sum(values):\n",
        "  # print(\"values\", values)\n",
        "  # max_value = 8\n",
        "  # return min(sum(values), max_value)\n",
        "  # return max(values)\n",
        "  # return min(values)\n",
        "  return sum(values)\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  saturated_total = (\n",
        "      pipeline\n",
        "      | 'Create plant counts' >> beam.Create([\n",
        "          ('ü•ï', 3),\n",
        "          ('ü•ï', 2),\n",
        "          ('üçÜ', 1),\n",
        "          ('üçÖ', 4),\n",
        "          ('üçÖ', 5),\n",
        "          ('üçÖ', 3),\n",
        "      ])\n",
        "      | 'Saturated sum' >> beam.CombinePerKey(saturated_sum)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oawbVYgqKn_",
        "outputId": "4d3c033d-b2b4-4f6d-fac3-b00311ac319b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ü•ï', 5)\n",
            "('üçÜ', 1)\n",
            "('üçÖ', 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "CombineValues:\n",
        "\n",
        "  Combines an iterable of values in a keyed collection of elements.\n",
        "\n",
        "  CombineValues accepts a function that takes an iterable of elements as an input, and combines them to return a single element.\n",
        "\n",
        "  CombineValues expects a keyed PCollection of elements, where the value is an iterable of elements to be combined.\n",
        "\n"
      ],
      "metadata": {
        "id": "xuAYLGB-ruf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with beam.Pipeline() as pipeline:\n",
        "  total = (\n",
        "      pipeline\n",
        "      | 'Create produce counts' >> beam.Create([\n",
        "          ('ü•ï', [3, 2]),\n",
        "          ('üçÜ', [1]),\n",
        "          ('üçÖ', [4, 5, 3]),\n",
        "      ])\n",
        "      | 'Sum' >> beam.CombineValues(sum)\n",
        "      | beam.Map(print))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxqSl0_7qTGu",
        "outputId": "1915e22f-f672-4d2f-806d-678f1fdea20b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ü•ï', 5)\n",
            "('üçÜ', 1)\n",
            "('üçÖ', 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrwQ55wUrzme"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}