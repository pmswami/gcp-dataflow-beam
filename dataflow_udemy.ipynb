{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ZHxFPN-oAT",
        "outputId": "cef92c9d-803a-4a94-8c69-41a16bfe94ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ],
      "source": [
        "print(\"hello world\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apache-beam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvL75dT4-wwl",
        "outputId": "7cca2164-f0e0-4373-cfa6-1bf5f0b5e6e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.64.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (4.23.0)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (3.3.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.26.4)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (24.1)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (3.20.3)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2024.2)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam)\n",
            "  Downloading redis-5.1.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2024.9.11)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (0.6)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam) (3.1.4)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.20.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2024.8.30)\n",
            "Downloading apache_beam-2.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.1.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.3/261.3 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: crcmod, dill, hdfs, pyjsparser, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=155402f5025cf7051a4e0b6c5931a82d486a9a83d1bfc9603c634d7cfc44b50c\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=c2a3e0f5ba5af8b6db6e0368bb1fa403ec200c7fcdfe65e68ec104cc8fe3cb73\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=ae080ac3b7d4ab30580eca01fc3a46fa6c418e7c518ec8097c993b0b199b15a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25983 sha256=a2f2b5ed1d9ab766cc9f5e1c398539d0abf74ed08c61f696d7e795ccad7157c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=350afd6e966f65538e2f8f9538de3c2e77d5586e989d080defe7ad9686caa68b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill hdfs pyjsparser docopt\n",
            "Installing collected packages: pyjsparser, docopt, crcmod, zstandard, redis, pydot, orjson, objsize, js2py, fasteners, fastavro, dnspython, dill, pymongo, hdfs, apache-beam\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.2\n",
            "    Uninstalling pydot-3.0.2:\n",
            "      Successfully uninstalled pydot-3.0.2\n",
            "Successfully installed apache-beam-2.59.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.9.7 fasteners-0.19 hdfs-2.7.3 js2py-0.74 objsize-0.7.0 orjson-3.10.7 pydot-1.4.2 pyjsparser-2.7.1 pymongo-4.10.1 redis-5.1.1 zstandard-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install apache-beam[interactive]"
      ],
      "metadata": {
        "id": "IJEACQtKyrn4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "OPdRmh7n_OnV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M72MIv6Q_b0c",
        "outputId": "c340dba4-f8e9-41c8-e5fa-1a7b0e1939a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload local data into colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "oTnVbQ-L_haL",
        "outputId": "4b7d01ef-23cf-4774-fed3-356abcabf50b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6d7aea07-6497-4fb8-9fff-a4dd83d1536e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6d7aea07-6497-4fb8-9fff-a4dd83d1536e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dept_data.txt to dept_data.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm2mj3kk_xS8",
        "outputId": "820ab898-8e98-435b-d60f-8b91d2068518"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  dept_data.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "p1 = beam.Pipeline()\n",
        "attendance_count=(\n",
        "    p1\n",
        "    | beam.io.ReadFromText('dept_data.txt')\n",
        "    | beam.io.WriteToText('/content/data/output.txt')\n",
        ")\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "MurMCo4w_4RF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "31b61b19-1e34-4da9-d649-5ae794265e51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe0b8d493c0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p2 = beam.Pipeline()\n",
        "\n",
        "lines= (p2\n",
        "        | beam.Create([\"jksdnfd\", \"sefdn\", \"asg\", \"askdsfhfjgasb\"])\n",
        "        | beam.io.WriteToText('/content/data/output2.txt')\n",
        "        )\n",
        "p2.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw4hx1q5yV6c",
        "outputId": "b7ad3b08-fd44-48a1-a6a6-269270e6772f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe0b7bede10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head \"/content/data/output2.txt-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk6nJd_k7U_M",
        "outputId": "26a6eaf1-ceca-435e-87b7-6949181c1895"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jksdnfd\n",
            "sefdn\n",
            "asg\n",
            "askdsfhfjgasb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p3 = beam.Pipeline()\n",
        "\n",
        "attendance_count=(\n",
        "    p3\n",
        "    | beam.Create([1,2,3,4,5,6,7,8,9])\n",
        "    | beam.io.WriteToText('/content/data/output3.txt')\n",
        ")\n",
        "p3.run()"
      ],
      "metadata": {
        "id": "3-iq4e_B7gN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b89d408-d8ec-4cbe-bc45-5d449b4e6556"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe0b7ce5e10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head \"/content/data/output3.txt-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAKrBLfNFwz7",
        "outputId": "b16d4e5a-d48c-4c74-e224-50be7b1d178c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p4= beam.Pipeline()\n",
        "\n",
        "p4_test = (p4\n",
        "           | beam.Create([(\"maths\", 100), (\"maths\", 100), (\"maths\", 100), (\"maths\", 100), (\"maths\", 100)])\n",
        "           | beam.io.WriteToText('/content/data/output4.txt')\n",
        "           )\n",
        "\n",
        "p4.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbviVQG4F6we",
        "outputId": "78a037d0-6280-4d8c-8333-c194e00116dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe0b9357a00>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! head \"/content/data/output4.txt-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p09WNMewHJUt",
        "outputId": "a8ea2266-a19c-4b33-f2e4-6703a0d0629b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('maths', 100)\n",
            "('maths', 100)\n",
            "('maths', 100)\n",
            "('maths', 100)\n",
            "('maths', 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p5= beam.Pipeline()\n",
        "\n",
        "p5_test = (p5\n",
        "           | beam.Create({\"row1\": [1,2,3], \"row2\":[4,5,6]})\n",
        "           | beam.io.WriteToText('/content/data/output5.txt')\n",
        "           )\n",
        "\n",
        "p5.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2qTDOb_HPZk",
        "outputId": "bbf5dadd-a4c4-4fa9-ecc2-bdae4925ba7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fe0b7362b90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head \"/content/data/output5.txt-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUjQXA-zHjg0",
        "outputId": "896cd894-17af-43df-c1e6-23abaf116eef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('row1', [1, 2, 3])\n",
            "('row2', [4, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map, FlatMap, Filter"
      ],
      "metadata": {
        "id": "3F42zfAyjJ4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "p6 = beam.Pipeline()\n",
        "attendance_count=(\n",
        "    p6\n",
        "    | beam.io.ReadFromText('dept_data.txt')\n",
        "    | beam.Map(lambda element: element.split(\",\"))\n",
        "    | beam.io.WriteToText('/content/data/output6.txt')\n",
        ")\n",
        "p6.run()\n",
        "\n",
        "!head \"/content/data/output6.txt-00000-of-00001\""
      ],
      "metadata": {
        "id": "DnqkvtZXHta0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b997300-0a09-4f40-b0ea-ca521ff1ba93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['149633CM', 'Marco', '10', 'Accounts', '1-01-2019']\n",
            "['212539MU', 'Rebekah', '10', 'Accounts', '1-01-2019']\n",
            "['231555ZZ', 'Itoe', '10', 'Accounts', '1-01-2019']\n",
            "['503996WI', 'Edouard', '10', 'Accounts', '1-01-2019']\n",
            "['704275DC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
            "['957149WC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
            "['241316NX', 'Kumiko', '10', 'Accounts', '1-01-2019']\n",
            "['796656IE', 'Gaston', '10', 'Accounts', '1-01-2019']\n",
            "['331593PS', 'Beryl', '20', 'HR', '1-01-2019']\n",
            "['560447WH', 'Olga', '20', 'HR', '1-01-2019']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "def splitElements(ele):\n",
        "  return ele.split(\",\")\n",
        "\n",
        "p7 = beam.Pipeline()\n",
        "attendance_count=(\n",
        "    p7\n",
        "    | beam.io.ReadFromText('dept_data.txt')\n",
        "    | beam.FlatMap(splitElements)\n",
        "    | beam.io.WriteToText('/content/data/output7.txt')\n",
        ")\n",
        "p7.run()\n",
        "\n",
        "!head \"/content/data/output7.txt-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT6_JpFqjFmY",
        "outputId": "69d9f247-39a2-49bf-9469-591964f14276"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149633CM\n",
            "Marco\n",
            "10\n",
            "Accounts\n",
            "1-01-2019\n",
            "212539MU\n",
            "Rebekah\n",
            "10\n",
            "Accounts\n",
            "1-01-2019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "def splitElements(ele):\n",
        "  return ele.split(\",\")\n",
        "\n",
        "def filtering(record):\n",
        "  return record[3] == \"Accounts\"\n",
        "\n",
        "p8 = beam.Pipeline()\n",
        "attendance_count=(\n",
        "    p8\n",
        "    | beam.io.ReadFromText('dept_data.txt')\n",
        "    | beam.Map(splitElements)\n",
        "    | beam.Filter(filtering)\n",
        "    | beam.Map(lambda ele: (ele[1], 1))\n",
        "    | beam.CombinePerKey(sum)\n",
        "    | beam.io.WriteToText('/content/data/output8.txt')\n",
        "    | \"Read from file\" >> beam.io.ReadFromText('dept_data.txt')\n",
        "    | \"Map transform\" >> beam.Map(splitElements)\n",
        "    | \"Filter the data\" >> beam.Filter(filtering)\n",
        "    | \"Map\">>beam.Map(lambda ele: (ele[1], 1))\n",
        "    | \"groupby\">>beam.CombinePerKey(sum)\n",
        "    | \"Write to file\">>beam.io.WriteToText('/content/data/output8.txt')\n",
        ")\n",
        "p8.run()\n",
        "\n",
        "!head -n 20 \"/content/data/output8.txt-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8WlYFkRkBnB",
        "outputId": "a9de74b4-dc40-47f1-eb63-a77f1d04e37f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:No shards found to finalize. num_shards: 1, skipped: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Marco', 31)\n",
            "('Rebekah', 31)\n",
            "('Itoe', 31)\n",
            "('Edouard', 31)\n",
            "('Kyle', 62)\n",
            "('Kumiko', 31)\n",
            "('Gaston', 31)\n",
            "('Ayumi', 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "def splitElements(ele):\n",
        "  return ele.split(\",\")\n",
        "\n",
        "def filtering(record):\n",
        "  return record[3] == \"Accounts\"\n",
        "\n",
        "with beam.Pipeline() as p9:\n",
        "  attendance_count=(\n",
        "      p9\n",
        "      # | beam.io.ReadFromText('dept_data.txt')\n",
        "      # | beam.Map(splitElements)\n",
        "      # | beam.Filter(filtering)\n",
        "      # | beam.Map(lambda ele: (ele[1], 1))\n",
        "      # | beam.CombinePerKey(sum)\n",
        "      # | beam.io.WriteToText('/content/data/output9.txt')\n",
        "      | \"Read from file\" >> beam.io.ReadFromText('dept_data.txt')\n",
        "      | \"Map transform\" >> beam.Map(splitElements)\n",
        "      | \"Filter the data\" >> beam.Filter(filtering)\n",
        "      | \"Map\">>beam.Map(lambda ele: (ele[1], 1))\n",
        "      | \"groupby\">>beam.CombinePerKey(sum)\n",
        "      | \"Write to file\">>beam.io.WriteToText('/content/data/output9.txt')\n",
        "  )\n",
        "\n",
        "!head -n 20 \"/content/data/output9.txt-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1skm-TgPkUFw",
        "outputId": "fb316b85-91cc-4a13-e1aa-a4e62600a45c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Marco', 31)\n",
            "('Rebekah', 31)\n",
            "('Itoe', 31)\n",
            "('Edouard', 31)\n",
            "('Kyle', 62)\n",
            "('Kumiko', 31)\n",
            "('Gaston', 31)\n",
            "('Ayumi', 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Branching"
      ],
      "metadata": {
        "id": "DKbEoUy9qz3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "def splitElements(ele):\n",
        "  return ele.split(\",\")\n",
        "\n",
        "with beam.Pipeline() as p10:\n",
        "  input_data=(\n",
        "      p10\n",
        "      | \"Read from file\" >> beam.io.ReadFromText('dept_data.txt')\n",
        "      | \"Map transform\" >> beam.Map(splitElements)\n",
        "  )\n",
        "  account_data = (\n",
        "      input_data\n",
        "      | \"Filter the accounts data\" >> beam.Filter(lambda record: record[3]==\"Accounts\")\n",
        "      | \"Map the accounts count\">>beam.Map(lambda record: (record[1], 1))\n",
        "      | \"groupby on accounts\">>beam.CombinePerKey(sum)\n",
        "      | \"Write accounts to file\">>beam.io.WriteToText('/content/data/output_accounts.txt')\n",
        "  )\n",
        "\n",
        "  hr_data = (\n",
        "      input_data\n",
        "      | \"Filter the hr data\" >> beam.Filter(lambda record: record[3]==\"Accounts\")\n",
        "      | \"Map the hr count\">>beam.Map(lambda record: (record[1], 1))\n",
        "      | \"groupby on hr\">>beam.CombinePerKey(sum)\n",
        "      | \"Write hr to file\">>beam.io.WriteToText('/content/data/output_hr.txt')\n",
        "  )\n",
        "\n",
        "  output_data = (\n",
        "      (account_data, hr_data)\n",
        "      | beam.Flatten()\n",
        "      | beam.io.WriteToText('/content/data/output_combined.txt')\n",
        "  )\n",
        "\n",
        "\n",
        "!head -n 20 \"/content/data/output_accounts.txt-00000-of-00001\"\n",
        "print()\n",
        "!head -n 20 \"/content/data/output_hr.txt-00000-of-00001\"\n",
        "print()\n",
        "!head -n 20 \"/content/data/output_combined.txt-00000-of-00001\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdEUNvnpnneo",
        "outputId": "92ece1dc-0783-4997-a4bf-a890f7a52448"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Marco', 31)\n",
            "('Rebekah', 31)\n",
            "('Itoe', 31)\n",
            "('Edouard', 31)\n",
            "('Kyle', 62)\n",
            "('Kumiko', 31)\n",
            "('Gaston', 31)\n",
            "('Ayumi', 30)\n",
            "\n",
            "('Marco', 31)\n",
            "('Rebekah', 31)\n",
            "('Itoe', 31)\n",
            "('Edouard', 31)\n",
            "('Kyle', 62)\n",
            "('Kumiko', 31)\n",
            "('Gaston', 31)\n",
            "('Ayumi', 30)\n",
            "\n",
            "/content/data/output_hr.txt-00000-of-00001\n",
            "/content/data/output_accounts.txt-00000-of-00001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ParDo Transform"
      ],
      "metadata": {
        "id": "EnhhIAgTycK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ParDo as Map function\n",
        "import apache_beam as beam\n",
        "\n",
        "class SplitRow(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    return [element.split(\",\")]\n",
        "\n",
        "with beam.Pipeline() as p11:\n",
        "  attendance_count=(\n",
        "      p11\n",
        "      | beam.io.ReadFromText('dept_data.txt')\n",
        "      # | beam.ParDo(SplitRow())\n",
        "      | beam.ParDo(lambda record: [record.split(\",\")])\n",
        "      | \"Write to file\">>beam.io.WriteToText('/content/data/output_pardo_p11.txt')\n",
        "  )\n",
        "\n",
        "!head -n 20 \"/content/data/output_pardo_p11.txt-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7J5nXHfswjq",
        "outputId": "686209a2-76fa-48c6-88e2-bdc1765d9c33"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['149633CM', 'Marco', '10', 'Accounts', '1-01-2019']\n",
            "['212539MU', 'Rebekah', '10', 'Accounts', '1-01-2019']\n",
            "['231555ZZ', 'Itoe', '10', 'Accounts', '1-01-2019']\n",
            "['503996WI', 'Edouard', '10', 'Accounts', '1-01-2019']\n",
            "['704275DC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
            "['957149WC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
            "['241316NX', 'Kumiko', '10', 'Accounts', '1-01-2019']\n",
            "['796656IE', 'Gaston', '10', 'Accounts', '1-01-2019']\n",
            "['331593PS', 'Beryl', '20', 'HR', '1-01-2019']\n",
            "['560447WH', 'Olga', '20', 'HR', '1-01-2019']\n",
            "['222997TJ', 'Leslie', '20', 'HR', '1-01-2019']\n",
            "['171752SY', 'Mindy', '20', 'HR', '1-01-2019']\n",
            "['153636AS', 'Vicky', '20', 'HR', '1-01-2019']\n",
            "['745411HT', 'Richard', '20', 'HR', '1-01-2019']\n",
            "['298464HN', 'Kirk', '20', 'HR', '1-01-2019']\n",
            "['783950BW', 'Kaori', '20', 'HR', '1-01-2019']\n",
            "['892691AR', 'Beryl', '20', 'HR', '1-01-2019']\n",
            "['245668UZ', 'Oscar', '20', 'HR', '1-01-2019']\n",
            "['231206QD', 'Kumiko', '30', 'Finance', '1-01-2019']\n",
            "['357919KT', 'Wendy', '30', 'Finance', '1-01-2019']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ParDo as FlatMap function\n",
        "import apache_beam as beam\n",
        "\n",
        "class SplitRow(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    return element.split(\",\")\n",
        "\n",
        "with beam.Pipeline() as p12:\n",
        "  attendance_count=(\n",
        "      p12\n",
        "      | beam.io.ReadFromText('dept_data.txt')\n",
        "      # | beam.ParDo(SplitRow())\n",
        "      | beam.ParDo(lambda record: record.split(\",\"))\n",
        "      | \"Write to file\">>beam.io.WriteToText('/content/data/output_pardo_p12.txt')\n",
        "  )\n",
        "\n",
        "!head -n 20 \"/content/data/output_pardo_p12.txt-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbCf-1Rg5CHk",
        "outputId": "86741493-76dc-441c-8252-16b83738080c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149633CM\n",
            "Marco\n",
            "10\n",
            "Accounts\n",
            "1-01-2019\n",
            "212539MU\n",
            "Rebekah\n",
            "10\n",
            "Accounts\n",
            "1-01-2019\n",
            "231555ZZ\n",
            "Itoe\n",
            "10\n",
            "Accounts\n",
            "1-01-2019\n",
            "503996WI\n",
            "Edouard\n",
            "10\n",
            "Accounts\n",
            "1-01-2019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ParDo as Filter function\n",
        "import apache_beam as beam\n",
        "\n",
        "class SplitRow(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    return [element.split(\",\")]\n",
        "\n",
        "class FilterAccountsEmployee(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    if element[3] == \"Accounts\":\n",
        "      return [element]\n",
        "\n",
        "class PairEmployees(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    return [(element[3] + \",\" + element[1], 1)]\n",
        "\n",
        "class Counting(beam.DoFn):\n",
        "  def process(self, element):\n",
        "    (key, values) = element\n",
        "    return [(key, sum(values))]\n",
        "\n",
        "with beam.Pipeline() as p13:\n",
        "  attendance_count=(\n",
        "      p13\n",
        "      | beam.io.ReadFromText('dept_data.txt')\n",
        "      | beam.ParDo(SplitRow())\n",
        "      | beam.ParDo(FilterAccountsEmployee())\n",
        "      | beam.ParDo(PairEmployees())\n",
        "      | \"Group\" >> beam.GroupByKey()\n",
        "      | \"Sum using ParDo\" >> beam.ParDo(Counting())\n",
        "      | \"Write to file\">>beam.io.WriteToText('/content/data/output_pardo_p13.txt')\n",
        "  )\n",
        "\n",
        "!head -n 20 \"/content/data/output_pardo_p13.txt-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXoVXhsW5fdE",
        "outputId": "9092164b-af36-408f-c86a-8826c4055741"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Accounts,Marco', 31)\n",
            "('Accounts,Rebekah', 31)\n",
            "('Accounts,Itoe', 31)\n",
            "('Accounts,Edouard', 31)\n",
            "('Accounts,Kyle', 62)\n",
            "('Accounts,Kumiko', 31)\n",
            "('Accounts,Gaston', 31)\n",
            "('Accounts,Ayumi', 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combiner\n",
        "\n",
        " Combiner is a mini reducer which does the reduce task locally to a mapper machine"
      ],
      "metadata": {
        "id": "kpI6vSM_FAM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "\n",
        "class AverageFn(beam.CombineFn):\n",
        "  def create_accumulator(self):\n",
        "    return (0.0, 0)\n",
        "\n",
        "  def add_input(self, sum_count, input):\n",
        "    (sum, count) = sum_count\n",
        "    return sum + input, count + 1\n",
        "\n",
        "  def merge_accumulators(self, accumulators):\n",
        "    ind_sums, ind_counts = zip(*accumulators)\n",
        "    return sum(ind_sums), sum(ind_counts)\n",
        "\n",
        "  def extract_output(self, sum_count):\n",
        "    (sum, count) = sum_count\n",
        "    return sum / count if count else float('NaN')\n",
        "\n",
        "with beam.Pipeline() as p14:\n",
        "  small_sum = (\n",
        "      p14\n",
        "      # | beam.Create([1,2,3,4,5,6,7,8,9])15,5,7,7,9,23,13,5\n",
        "      | beam.Create([15,5,7,7,9,23,13,5])\n",
        "      | beam.CombineGlobally(AverageFn())\n",
        "      | beam.io.WriteToText('/content/data/output_p14.txt')\n",
        "  )\n",
        "!head -n 20 \"/content/data/output_p14.txt-00000-of-00001\""
      ],
      "metadata": {
        "id": "3ylTEntG58HM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef170171-4c08-46f5-e459-a45c0a1cd8a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter the data\n",
        "import apache_beam as beam\n",
        "\n",
        "def SplitRow(element):\n",
        "  return element.split(\",\")\n",
        "\n",
        "with beam.Pipeline() as p15:\n",
        "  input_data = (\n",
        "      p15\n",
        "      | beam.io.ReadFromText('dept_data.txt')\n",
        "      | beam.Map(SplitRow)\n",
        "      # | beam.Map(print)\n",
        "  )\n",
        "\n",
        "  accounts_data = (\n",
        "      input_data\n",
        "      | \"filter accounts data\" >> beam.Filter(lambda record: record[3] == \"Accounts\")\n",
        "      | \"map accounts data\" >> beam.Map(lambda record: (record[1], 1))\n",
        "      | \"combine accounts data\" >> beam.CombinePerKey(sum)\n",
        "      # | \"print accounts data\" >> beam.Map(print)\n",
        "      | \"write accounts data\" >> beam.io.WriteToText('/content/data/output_accounts_p15.txt')\n",
        "  )\n",
        "\n",
        "  hr_data = (\n",
        "      input_data\n",
        "      | \"filter hr data\" >> beam.Filter(lambda record: record[3] == \"HR\")\n",
        "      | \"map hr data\" >> beam.Map(lambda record: (record[1], 1))\n",
        "      | \"combine hr\" >> beam.CombinePerKey(sum)\n",
        "      # | \"print hr data\" >> beam.Map(print)\n",
        "      | \"write hr data\" >> beam.io.WriteToText('/content/data/output_hr_p15.txt')\n",
        "  )\n",
        "\n",
        "!head -n 10 /content/data/output_accounts_p15.txt*\n",
        "print()\n",
        "!head -n 10 /content/data/output_hr_p15.txt*\n"
      ],
      "metadata": {
        "id": "5GNQwaMpAmCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c48ace2e-2967-4860-8cf6-c952afb7a488"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Marco', 31)\n",
            "('Rebekah', 31)\n",
            "('Itoe', 31)\n",
            "('Edouard', 31)\n",
            "('Kyle', 62)\n",
            "('Kumiko', 31)\n",
            "('Gaston', 31)\n",
            "('Ayumi', 30)\n",
            "\n",
            "('Beryl', 62)\n",
            "('Olga', 31)\n",
            "('Leslie', 31)\n",
            "('Mindy', 31)\n",
            "('Vicky', 31)\n",
            "('Richard', 31)\n",
            "('Kirk', 31)\n",
            "('Kaori', 31)\n",
            "('Oscar', 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter the data\n",
        "import apache_beam as beam\n",
        "\n",
        "def SplitRow(element):\n",
        "  return element.split(\",\")\n",
        "\n",
        "def FilterOnCount(record):\n",
        "  name, count = record\n",
        "  if count > 30:\n",
        "    return record\n",
        "\n",
        "with beam.Pipeline() as p16:\n",
        "  input_data = (\n",
        "      p16\n",
        "      | beam.io.ReadFromText('dept_data.txt')\n",
        "      | beam.Map(SplitRow)\n",
        "      # | beam.Map(print)\n",
        "  )\n",
        "\n",
        "  accounts_data = (\n",
        "      input_data\n",
        "      | \"filter accounts data\" >> beam.Filter(lambda record: record[3] == \"Accounts\")\n",
        "      | \"map accounts data\" >> beam.Map(lambda record: (record[1], 1))\n",
        "      | \"combine accounts data\" >> beam.CombinePerKey(sum)\n",
        "      # | \"print accounts data\" >> beam.Map(print)\n",
        "      | \"filter on count for accounts\" >> beam.Filter(FilterOnCount)\n",
        "      | \"write accounts data\" >> beam.io.WriteToText('/content/data/output_accounts_p16.txt')\n",
        "  )\n",
        "\n",
        "  hr_data = (\n",
        "      input_data\n",
        "      | \"filter hr data\" >> beam.Filter(lambda record: record[3] == \"HR\")\n",
        "      | \"map hr data\" >> beam.Map(lambda record: (record[1], 1))\n",
        "      | \"combine hr\" >> beam.CombinePerKey(sum)\n",
        "      # | \"print hr data\" >> beam.Map(print)\n",
        "      | \"filter on count for hr\" >> beam.Filter(FilterOnCount)\n",
        "      | \"write hr data\" >> beam.io.WriteToText('/content/data/output_hr_p16.txt')\n",
        "  )\n",
        "\n",
        "!head -n 10 /content/data/output_accounts_p16.txt*\n",
        "print()\n",
        "!head -n 10 /content/data/output_hr_p16.txt*\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAJfrWLnS0TH",
        "outputId": "5a1f0970-7529-4c0b-8208-798e262f6fe4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Marco', 31)\n",
            "('Rebekah', 31)\n",
            "('Itoe', 31)\n",
            "('Edouard', 31)\n",
            "('Kyle', 62)\n",
            "('Kumiko', 31)\n",
            "('Gaston', 31)\n",
            "\n",
            "('Beryl', 62)\n",
            "('Olga', 31)\n",
            "('Leslie', 31)\n",
            "('Mindy', 31)\n",
            "('Vicky', 31)\n",
            "('Richard', 31)\n",
            "('Kirk', 31)\n",
            "('Kaori', 31)\n",
            "('Oscar', 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Composite Transform**"
      ],
      "metadata": {
        "id": "Pzmdr2uzV3GL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter the data\n",
        "import apache_beam as beam\n",
        "\n",
        "class CompositeTransform(beam.PTransform):\n",
        "  def expand(self, input_collection):\n",
        "    tmp = (\n",
        "        input_collection\n",
        "        | \"combine accounts data\" >> beam.CombinePerKey(sum)\n",
        "        # | \"print accounts data\" >> beam.Map(print)\n",
        "        | \"filter on count for accounts\" >> beam.Filter(FilterOnCount)\n",
        "        | \"regular frmat employee\" >> beam.Map(format_output)\n",
        "    )\n",
        "    return tmp\n",
        "\n",
        "def format_output(record):\n",
        "  name, count = record\n",
        "  return \", \".join((name, str(count), \"regular employee\"))\n",
        "\n",
        "def SplitRow(element):\n",
        "  return element.split(\",\")\n",
        "\n",
        "def FilterOnCount(record):\n",
        "  name, count = record\n",
        "  if count > 30:\n",
        "    return record\n",
        "\n",
        "with beam.Pipeline() as p17:\n",
        "  input_data = (\n",
        "      p17\n",
        "      | beam.io.ReadFromText('dept_data.txt')\n",
        "      | beam.Map(SplitRow)\n",
        "      # | beam.Map(print)\n",
        "  )\n",
        "\n",
        "  accounts_data = (\n",
        "      input_data\n",
        "      | \"filter accounts data\" >> beam.Filter(lambda record: record[3] == \"Accounts\")\n",
        "      | \"map accounts data\" >> beam.Map(lambda record: (record[1], 1))\n",
        "      # # | \"combine accounts data\" >> beam.CombinePerKey(sum)\n",
        "      # # | \"print accounts data\" >> beam.Map(print)\n",
        "      # # | \"filter on count for accounts\" >> beam.Filter(FilterOnCount)\n",
        "      | \"composite transform for accounts\" >> CompositeTransform()\n",
        "      # | \"print accounts data\" >> beam.Map(print)\n",
        "      | \"write accounts data\" >> beam.io.WriteToText('/content/data/output_accounts_p17.txt')\n",
        "  )\n",
        "\n",
        "  hr_data = (\n",
        "      input_data\n",
        "      | \"filter hr data\" >> beam.Filter(lambda record: record[3] == \"HR\")\n",
        "      | \"map hr data\" >> beam.Map(lambda record: (record[1], 1))\n",
        "      # | \"combine hr\" >> beam.CombinePerKey(sum)\n",
        "      # | \"print hr data\" >> beam.Map(print)\n",
        "      # | \"filter on count for hr\" >> beam.Filter(FilterOnCount)\n",
        "      | \"composite transform for hr\" >> CompositeTransform()\n",
        "      | \"write hr data\" >> beam.io.WriteToText('/content/data/output_hr_p17.txt')\n",
        "  )\n",
        "\n",
        "!head -n 10 /content/data/output_accounts_p17.txt*\n",
        "print()\n",
        "!head -n 10 /content/data/output_hr_p17.txt*\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG9DTlO0Vhzd",
        "outputId": "28df8067-528e-43d5-b941-cdf51760bed7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marco, 31, regular employee\n",
            "Rebekah, 31, regular employee\n",
            "Itoe, 31, regular employee\n",
            "Edouard, 31, regular employee\n",
            "Kyle, 62, regular employee\n",
            "Kumiko, 31, regular employee\n",
            "Gaston, 31, regular employee\n",
            "\n",
            "Beryl, 62, regular employee\n",
            "Olga, 31, regular employee\n",
            "Leslie, 31, regular employee\n",
            "Mindy, 31, regular employee\n",
            "Vicky, 31, regular employee\n",
            "Richard, 31, regular employee\n",
            "Kirk, 31, regular employee\n",
            "Kaori, 31, regular employee\n",
            "Oscar, 31, regular employee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qg0m90lqXLoX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}